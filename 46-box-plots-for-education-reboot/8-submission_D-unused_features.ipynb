{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/44544766/ddg#44547144\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_read_csv(fn:str):\n",
    "    x = pd.read_csv(fn, na_values=['NO_LABEL', '(blank)'])\n",
    "    assert not x['Unnamed: 0'].duplicated().any()\n",
    "    x = x.set_index(\"Unnamed: 0\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd_read_csv('data_in/TrainingData.csv')\n",
    "test = pd_read_csv('data_in/TestData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.columns\n",
    "train['Position_Type'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(train.columns).intersection(set(test.columns)) - set(['FTE','Total']))\n",
    "features.sort()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = set(train.columns) - set(test.columns)\n",
    "target = list(target)\n",
    "target.sort()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in target:\n",
    "    test[col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_holdout'] = False\n",
    "test ['is_holdout'] = True\n",
    "df = pd.concat([train,test], axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse FTE for classification\n",
    "\n",
    "# df['FTE'].value_counts().iloc[:60].sum(), df['FTE'].value_counts().iloc[60:].sum(), pd.isnull(df['FTE']).sum()\n",
    "# df['FTE'].value_counts().head(n=40).sum()\n",
    "\n",
    "# df['FTE2'] = df['FTE'].round(1)\n",
    "\n",
    "df['FTE'].apply(lambda x: 'nan' if pd.isnull(x) else ( str(round(x,1)) if x <=1 else '>1' ) ).value_counts() # .shape # .tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert FTE to string boolean and append to list of features\n",
    "# df['FTE'] = ~pd.isnull(df['FTE']).astype('str')\n",
    "df['FTE'] = df['FTE'].apply(lambda x: 'nan' if pd.isnull(x) else ( str(round(x,1)) if x <=1 else '>1' ) )\n",
    "features = features + ['FTE']\n",
    "features.sort()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = list(set(df.columns) - set(features) - set(target))\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df[features].shape, df[target].shape, df[meta].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze how close the train and test features are"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(len(features)):\n",
    "    print(\n",
    "        i,\n",
    "        'train - test', \n",
    "        len(set(train[features[0]]) - set(test [features[0]])),\n",
    "        'test - train',\n",
    "        len(set(test [features[0]]) - set(train[features[0]]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for ff in features:\n",
    "    vc_train = train[ff].value_counts()\n",
    "    vc_test  = test [ff].value_counts()\n",
    "    # vc_train.shape, vc_test.shape\n",
    "    vc_both  = vc_train.reset_index().merge(\n",
    "        vc_test.reset_index(), \n",
    "        left_on = 'index', \n",
    "        right_on='index', \n",
    "        how='outer', \n",
    "        suffixes=['_train', '_test']\n",
    "    )\n",
    "    vc_both = vc_both.set_index('index')\n",
    "    # vc_both.head()\n",
    "    # vc_both[pd.isnull(vc_both['Facility_or_Department_test'])].head()\n",
    "    out = {\n",
    "        'feature': ff,\n",
    "        'train all': train.shape[0],\n",
    "        # 'train': vc_both['%s_train'%ff].sum(),\n",
    "        'train non-null': (~pd.isnull(train[ff])).sum(),\n",
    "        'train_minus_test': vc_both['%s_train'%ff][pd.isnull(vc_both['%s_test'%ff ])].sum(), \n",
    "        'test_minus_train': vc_both['%s_test'%ff ][pd.isnull(vc_both['%s_train'%ff])].sum(),\n",
    "    }\n",
    "    out['tmt_pct'] = out['test_minus_train'] * 100 // out['train non-null']\n",
    "    results.append(out)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results = results.set_index('feature').sort_index()\n",
    "results = results.astype('uint32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.shape\n",
    "# results.head()\n",
    "results[['train all', 'train non-null', 'train_minus_test', 'test_minus_train', 'tmt_pct']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sod = train['Sub_Object_Description'].value_counts()\n",
    "sod = test['Sub_Object_Description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# plt.bar(x=range(sod.shape[0]), height=sod.values)\n",
    "plt.bar(x=range(sod.shape[0]-5), height=sod.iloc[5:].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sod[sod<10].shape[0], sod.shape[0]\n",
    "sod[sod<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtest = test['Sub_Object_Description'].apply(lambda x: (~pd.isnull(x)) & ('community' in str(x).lower())) # .sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Sub_Object_Description'][subtest].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "labels = yaml.load(open(\"labels.yml\",'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function': ['Aides Compensation\n",
    "prediction_names = []\n",
    "for k,v1 in labels.items():\n",
    "    for v2 in v1:\n",
    "        pn = \"%s__%s\"%(k,v2)\n",
    "        prediction_names.append(pn)\n",
    "        \n",
    "        \n",
    "assert 'Function__Aides Compensation' in prediction_names\n",
    "prediction_names.sort()\n",
    "prediction_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot encode each target by its classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in prediction_names: df[p] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v1 in labels.items():\n",
    "    for v2 in v1:\n",
    "        pn = \"%s__%s\"%(k,v2)\n",
    "        # print(pn)\n",
    "        df[pn] = df[k] == v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since NO_LABEL is replaced with NaN, need this\n",
    "for dependent in labels.keys():\n",
    "    target_sub = [x for x in df.columns if x.startswith(\"%s__\"%dependent)]\n",
    "    df.loc[~df[target_sub].any(axis=1), '%s__NO_LABEL'%dependent]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Function', 'Function__Teacher Compensation', 'Function__Substitute Compensation', 'Function__NO_LABEL']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df[pd.isnull(df[prediction_names]).all(axis=1)].shape, df.loc[~df[prediction_names].any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ~pd.isnull(df[prediction_names]).any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[prediction_names] = df[prediction_names].astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.ctime())\n",
    "df_feat = df[features].apply(lambda x: pd.factorize(x)[0], axis=0)\n",
    "df_feat = df_feat + 1 # +1 for the -1 from pd.factorize on nan (keras Embedding supports [0,N) )    \n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat.max().max(), df_feat.min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = df_feat.max(axis=0) + 1 # +1 to count the 0 index\n",
    "vocab_size = vocab_size.sort_index()\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df[prediction_names].max().max()==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the non-holdout into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_feat[~df['is_holdout']]\n",
    "y = df[prediction_names][~df['is_holdout']] # .fillna(0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# test_size=0.33\n",
    "test_size=0\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=42)\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate label_keys array whose order is replicable\n",
    "label_keys = labels.keys()\n",
    "label_keys = list(label_keys)\n",
    "label_keys.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build a dummy equi-probable target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_equi = {}\n",
    "for k in label_keys:\n",
    "    y_equi[k] = np.ones(shape=(y_train.shape[0], len(labels[k]))) / len(labels[k])\n",
    "\n",
    "y_equi = [y_equi[k] for k in label_keys]\n",
    "y_equi = np.concatenate(y_equi, axis=1)\n",
    "y_equi = pd.DataFrame(y_equi, columns=y_train.columns, index=y_train.index)\n",
    "y_equi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_equi.head()\n",
    "# y_equi[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras embedding + Dense/LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dense, Flatten, LSTM, Input, Concatenate, Add, Lambda, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "\n",
    "def build_fn():\n",
    "\n",
    "    # vocab_size = stats.shape[0]\n",
    "\n",
    "    # inputs = [Input(shape=(prob3.shape[1],)) for f in vocab_size.index]\n",
    "    inputs = {f: Input(shape=(1,), name=f) for f in vocab_size.index}\n",
    "\n",
    "    # embeddings = [Embedding(vocab_size[f], embedding_dim, input_length=prob3.shape[1]) for f in vocab_size.index]\n",
    "\n",
    "    if True:\n",
    "        embedding_dim = 10 # 3 # 12 # 2 # 64 # FIXME\n",
    "        embeddings = {f: Embedding(vocab_size[f], embedding_dim, input_length=1)(inputs[f]) for f in vocab_size.index}\n",
    "    else:\n",
    "        embeddings = {f: Embedding(vocab_size[f], max(3, vocab_size[f]//15//10), input_length=1)(inputs[f]) for f in vocab_size.index}\n",
    "\n",
    "    # the model will take as input an integer matrix of size (batch, input_length).\n",
    "    # the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).\n",
    "    # now model.output_shape == (None, input_length, embedding_dim), where None is the batch dimension.\n",
    "\n",
    "    # dummy variable\n",
    "    x1= embeddings\n",
    "\n",
    "    #  flatten each feature since no sequences anyway\n",
    "    x1 = {f: Flatten(name=\"%s_flat\"%f)(x1[f]) for f in vocab_size.index}\n",
    "\n",
    "    # dense layer for each feature\n",
    "    # x1 = {f: Dense(10, activation = 'relu', name=\"%s_d01\"%f)(x1[f]) for f in vocab_size.index}\n",
    "    # x1 = {f: Dense( 3, activation = 'relu', name=\"%s_d02\"%f)(x1[f]) for f in vocab_size.index}\n",
    "\n",
    "    # a dropout for each feature, this way, the network is more robust to dependencies on a single feature\n",
    "    x1 = {f: Dropout(0.3, name=\"%s_dropout\"%f)(x1[f]) for f in vocab_size.index}\n",
    "\n",
    "    x1 = [x1[f] for f in vocab_size.index]\n",
    "    x1 = Concatenate()(x1)\n",
    "    # x1 = Flatten()(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "\n",
    "    x1 = Dense(1000, activation='relu')(x1)\n",
    "    x1 = Dense( 300, activation='relu')(x1)\n",
    "\n",
    "    # x1 = Dense( 50, activation='relu')(x1)\n",
    "    # o1 = {dependent: Dense(50, activation = 'relu', name=\"%s_d1\"%dependent)(x1) for dependent in label_keys}\n",
    "    # o1 = {dependent: Dense(50, activation = 'relu', name=\"%s_d2\"%dependent)(o1[dependent]) for dependent in label_keys}\n",
    "\n",
    "    # outputs = [Dense(len(labels[dependent]), activation = 'softmax', name=\"%s_out\"%dependent)(o1[dependent]) for dependent in label_keys]\n",
    "    outputs = [Dense(len(labels[dependent]), activation = 'softmax', name=\"%s_out\"%dependent)(x1) for dependent in label_keys]\n",
    "\n",
    "    inputs = [inputs[f] for f in vocab_size.index]\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    # model.compile('rmsprop', loss=multi_multiclass_logloss, metrics=['acc'])\n",
    "    # model.compile('rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    model.compile('adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import BaseWrapper\n",
    "\n",
    "class BaseWrapper2(BaseWrapper):\n",
    "    \"\"\"\n",
    "    Mostly just a copy of the original class in order to introduce preprocess_feature and preprocess_target\n",
    "    \"\"\"\n",
    "    def fit(self, x, y, **kwargs):\n",
    "        if self.build_fn is None:\n",
    "            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n",
    "        elif (not isinstance(self.build_fn, types.FunctionType) and\n",
    "              not isinstance(self.build_fn, types.MethodType)):\n",
    "            self.model = self.build_fn(\n",
    "                **self.filter_sk_params(self.build_fn.__call__))\n",
    "        else:\n",
    "            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    "\n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "\n",
    "        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n",
    "        fit_args.update(kwargs)\n",
    "        \n",
    "        # new lines\n",
    "        x = self.preprocess_feature(x) # <<<<<<<\n",
    "        y = self.preprocess_target(y) # <<<<<<<\n",
    "\n",
    "        history = self.model.fit(x, y, **fit_args)\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "class KerasClassifier2(KerasClassifier):\n",
    "    def fit(self, x, y, **kwargs):\n",
    "        y = np.array(y)\n",
    "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
    "            self.classes_ = np.arange(y.shape[1])\n",
    "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = np.searchsorted(self.classes_, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        return super(KerasClassifier, self).fit(x, y, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(KerasClassifier):\n",
    "    def preprocess_feature(self, x):\n",
    "        \"\"\"\n",
    "        convert 2-D matrix of features into array of 1-D features\n",
    "        This is needed because each feature has a different vocabulary for its embedding\n",
    "        \"\"\"\n",
    "        x = [x[f].values for f in vocab_size.index]\n",
    "        return x\n",
    "    \n",
    "    def preprocess_target(self, y):\n",
    "        \"\"\"\n",
    "        convert 2-D matrix of targets into K arrays of C-D matrices \n",
    "        where C is the number of classes of each target\n",
    "        \"\"\"\n",
    "        y = [y[[x for x in prediction_names if x.startswith(\"%s__\"%f)]].values for f in label_keys]\n",
    "        return y\n",
    "    \n",
    "    def fit(self, x, y, **kwargs):\n",
    "        x = self.preprocess_feature(x)\n",
    "        y = self.preprocess_target(y)\n",
    "        super().fit(x,y,**kwargs)\n",
    "        \n",
    "    def predict(self, x, **kwargs):\n",
    "        x = self.preprocess_feature(x)\n",
    "        super().predict(x,**kwargs)\n",
    "        \n",
    "    def predict_proba(self, x, **kwargs):\n",
    "        x = self.preprocess_feature(x)\n",
    "        super().predict_proba(x,**kwargs)\n",
    "        \n",
    "    def score(self, x, y, **kwargs):\n",
    "        x = self.preprocess_feature(x)\n",
    "        super().score(x,**kwargs)\n",
    "        \n",
    "    def __call__():\n",
    "        build_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_clf = MyNetwork(build_fn=None, epochs=30, batch_size=32*32, verbose=0)\n",
    "\n",
    "# from sklearn.cross_validation import StratifiedKFold\n",
    "# skf = cross_validation.StratifiedKFold(y_train, n_folds=3, shuffle=True)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "model = CalibratedClassifierCV(keras_clf, cv=skf, method='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then train to actual probabilities\n",
    "history = model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, batch_size = 32*32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## argmax accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "my_score = np.zeros(y_test.shape[0], dtype='uint8')\n",
    "# y_pred, sum_pred = model.predict([x_test[f].values for f in vocab_size.index])\n",
    "y_pred = model.predict([x_test[f].values for f in vocab_size.index])\n",
    "for i in range(y_test.shape[0]):\n",
    "    v1 = y_test.iloc[i].idxmax()\n",
    "    v2 = probabilities.columns[np.argmax(y_pred[i])]\n",
    "    my_score[i] = 1 if (v1 == v2) else 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sum(my_score), my_score.shape[0], sum(my_score)*100 // my_score.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_labels = labels\n",
    "sub_labels = {k:labels[k] for k in label_keys if k in ['Function']}\n",
    "\n",
    "n_show = 1000\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,v0 in enumerate(sub_labels.items()):\n",
    "    k,v1 = v0\n",
    "    y_pred2 = pd.DataFrame(y_pred[i], columns=v1)\n",
    "    y_test2 = pd.DataFrame(y_test[i], columns=v1)\n",
    "    for v2 in v1:\n",
    "        plt.figure(figsize=(20,3))\n",
    "        plt.plot(y_pred2.loc[:n_show,v2], label='pred')\n",
    "        #plt.plot(sum_pred, label='sum_pred', alpha=0.2)\n",
    "        plt.plot(y_test2.loc[:n_show,v2], '.', label='actual')\n",
    "        plt.legend(loc='best')\n",
    "        plt.title(\"%s: %s\"%(k,v2))\n",
    "\n",
    "        axes = plt.gca()\n",
    "        axes.set_ylim([-.1,1.1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0][0,:].sum(), y_pred[0][0,:].sum() # , y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## temporal comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred2 = {label_keys[i]: y_pred[i] for i in range(len(label_keys))}\n",
    "y_test2 = {label_keys[i]: y_test[i] for i in range(len(label_keys))}\n",
    "\n",
    "k2 = 'Function'\n",
    "y_pred3 = y_pred2[k2]\n",
    "y_test3 = y_test2[k2]\n",
    "\n",
    "for i in range(15):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.bar(x=range(y_pred3.shape[1]), height=y_test3[i])\n",
    "    plt.title('%s. actual, argmax=%s'%(i,np.argmax(y_test3[i])))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([-.1,1.1])\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.bar(x=range(y_pred3.shape[1]), height=y_pred3[i])\n",
    "    plt.title('%s. prediction, argmax=%s'%(i,np.argmax(y_pred3[i])))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([-.1,1.1])\n",
    "    \n",
    "    # plt.title(y_test.index[i])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=6\n",
    "y_test3[i,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ho = df_feat[features][~df['is_holdout']].head()\n",
    "x_ho  = [x_ho [f].values for f in vocab_size.index]\n",
    "y_ho = model.predict(x_ho)\n",
    "df_submit = pd.DataFrame(np.concatenate(y_ho, axis=1), columns=prediction_names)\n",
    "df_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ho = df_feat[features][ df['is_holdout']]\n",
    "x_ho  = [x_ho [f].values for f in vocab_size.index]\n",
    "y_ho = model.predict(x_ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_ho), y_ho[0].shape, y_ho[1].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_ho  = df[ df['is_holdout']]\n",
    "df_nho = df[~df['is_holdout']]\n",
    "df_ho.shape, df_ho[df_ho['joined'].isin(df_nho['joined'])].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_ho[features].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_ho[features].head(n=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_ho['joined'].head(n=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_nho[df_nho['Sub_Object_Description']==\"Line Item that is paid with Campus' money\"].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['is_holdout'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame(np.concatenate(y_ho, axis=1), columns=prediction_names, index=df_feat[ df['is_holdout']].index)\n",
    "df_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(df_submit['Use__NO_LABEL'].sort_values().values)\n",
    "plt.plot(df_submit['Operating_Status__NO_LABEL'].sort_values().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (df_submit['Operating_Status__NO_LABEL']<0.0001).all()\n",
    "del df_submit['Operating_Status__NO_LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'data_out/submission_C4_%s.csv'%(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "df_submit.to_csv(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare to C3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'data_out/submission_C3_20180409_120904.csv'\n",
    "df_c3 = pd.read_csv(fn).set_index(\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_submit - df_c3).head(n=2).apply(lambda x: x.idxmax(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[180042,28872], ['FTE']].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (df_submit - df_c3).max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape[0], result[abs(result) > 0.4].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df_submit.apply(lambda x: x.idxmax(), axis=1) != df_c3.apply(lambda x: x.idxmax(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=None, random_state=0, verbose=2, n_jobs=-1)\n",
    "\n",
    "\n",
    "regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(prob3.columns, regr.feature_importances_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(regr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred_rf = regr.predict(x_test[:3]) # .round(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred_rf.sum(axis=1), y_pred_rf[0], y_test[:3].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
