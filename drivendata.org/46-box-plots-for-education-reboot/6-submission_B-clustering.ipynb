{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/44544766/ddg#44547144\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_read_csv(fn:str):\n",
    "    x = pd.read_csv(fn, na_values=['NO_LABEL', '(blank)'])\n",
    "    assert not x['Unnamed: 0'].duplicated().any()\n",
    "    x = x.set_index(\"Unnamed: 0\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd_read_csv('data_in/TrainingData.csv')\n",
    "test = pd_read_csv('data_in/TestData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Position_Type'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_raw = list(set(train.columns).intersection(set(test.columns)) - set(['FTE','Total']))\n",
    "features_raw.sort()\n",
    "features_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = set(train.columns) - set(test.columns)\n",
    "target = list(target)\n",
    "target.sort()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in target:\n",
    "    test[col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_holdout'] = False\n",
    "test ['is_holdout'] = True\n",
    "df = pd.concat([train,test], axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = list(set(df.columns) - set(features_raw) - set(target))\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df[features_raw].shape, df[target].shape, df[meta].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer, FeatureHasher\n",
    "import re\n",
    "n_features = 2 ** 18\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "def tokens(doc):\n",
    "    \"\"\"Extract tokens from doc.\n",
    "\n",
    "    This uses a simple regex to break strings into tokens. For a more\n",
    "    principled approach, see CountVectorizer or TfidfVectorizer.\n",
    "    \"\"\"\n",
    "    return (tok.lower() for tok in re.findall(r\"\\w+\", doc))\n",
    "\n",
    "\n",
    "hasher = FeatureHasher(n_features=n_features, input_type=\"string\")\n",
    "\n",
    "df_labels = {}\n",
    "df_centers = {}\n",
    "for tokenize_column in features_raw: # 'Function_Description'\n",
    "    print(tokenize_column)\n",
    "    \n",
    "    x_in = df[tokenize_column].head(n=2000000000).fillna('')\n",
    "    x_in = x_in[~x_in.duplicated()]\n",
    "    # x_in.shape # 705\n",
    "\n",
    "    X = hasher.transform(tokens(d) for d in x_in)\n",
    "\n",
    "    # X = sparse_random_matrix(100, 100, density=0.01, random_state=42)\n",
    "    svd = TruncatedSVD(n_components=3, n_iter=17, random_state=42)\n",
    "    svd.fit(X)  \n",
    "\n",
    "    #print(svd.explained_variance_ratio_)  \n",
    "    # print(svd.explained_variance_ratio_.sum())  \n",
    "    # print(svd.singular_values_)  \n",
    "\n",
    "    Y = svd.transform(X)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=10, random_state=0, n_jobs=-1).fit(Y)\n",
    "\n",
    "    # len(set(kmeans.labels_)), kmeans.labels_\n",
    "    df_centers[tokenize_column] = Y\n",
    "    df_labels[ tokenize_column] = pd.DataFrame({'label': kmeans.labels_, 'value': x_in})\n",
    "\n",
    "    \n",
    "len(df_labels), len(df_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the label for value=\"\" with \"-1\"\n",
    "for x in df_labels:\n",
    "    print(x)\n",
    "    df_labels[x].loc[df_labels[x]['value']=='', 'label'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{x: len(df_labels[x]) for x in df_labels.keys()}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://keras.io/preprocessing/text/\n",
    "from keras.preprocessing.text import *\n",
    "\n",
    "# tokenize_column = 'Function'\n",
    "tt=Tokenizer(num_words=x_in.shape[0])\n",
    "tt.fit_on_texts(x_in)\n",
    "tokenized = [\"\".join([str(y) for y in x]) for x in tt.texts_to_sequences(x_in)]\n",
    "# tt.sequences_to_matrix(tt.texts_to_sequences(x_in))\n",
    "\n",
    "len(set(x_in)), len(set(tokenized))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result = pd.DataFrame({\n",
    "    'actual': x_in,\n",
    "    'tokenized': tokenized,\n",
    "    'int': pd.factorize(tokenized)[0],\n",
    "}).sort_values(['actual', 'tokenized', 'int'])\n",
    "result\n",
    "#df.shape, len(tokenized), tokenized.index('1011'), \n",
    "#df.loc[tokenized=='1011','Function'].head()\n",
    "# df.loc[pd.Series(tokenized)=='1011', 'Function'].head(n=20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "Y = df_centers['Function_Description']\n",
    "print(Y.shape)\n",
    "\n",
    "plt.plot(Y[:,0], Y[:,1], '.', alpha=0.1)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Y[:,0], Y[:,2], '.', alpha=0.1)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Y[:,1], Y[:,2], '.', alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://plot.ly/python/line-and-scatter/\n",
    "# import plotly.plotly as py\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "py.init_notebook_mode()\n",
    "\n",
    "# Create a trace\n",
    "for d1,d2 in ((0,1), (0,2), (1,2)):\n",
    "    trace = go.Scatter(\n",
    "        x = Y[:,d1],\n",
    "        y = Y[:,d2],\n",
    "        #z = Y[:,2],\n",
    "        marker=dict(\n",
    "            size='8',\n",
    "            color = df_labels['Function_Description'], #set color equal to a variable\n",
    "            colorscale='Viridis',\n",
    "            showscale=True\n",
    "        ),\n",
    "        mode = 'markers',\n",
    "        text = x_in,\n",
    "        textposition='top right'\n",
    "    )\n",
    "\n",
    "    data = [trace]\n",
    "\n",
    "    # Plot and embed in ipython notebook!\n",
    "    py.iplot(data, filename='basic-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# append to originator features\n",
    "print(df.shape)\n",
    "features_clustered = [(x, '%s_clustered'%x) for x in features_raw]\n",
    "for f1,f2 in features_clustered:\n",
    "    print(f1,f2)\n",
    "\n",
    "    df = df.merge(df_labels[f1], left_on=f1, right_on='value', how='left')\n",
    "    del df['value']\n",
    "\n",
    "    # now replace the numeric label above\n",
    "    # with the 1st \"original\" label with this numeric label\n",
    "    df_syn = df_labels[f1]\n",
    "    df_syn = df_syn[~df_syn['label'].duplicated()]\n",
    "    \n",
    "    #print(df.merge(df_labels[f1], left_on=f1, right_on='value', how='left')[['Facility_or_Department', 'label']].head(n=20).tail(n=10))\n",
    "    #print(df.merge(df_syn,      left_on=f1, right_on='value', how='left')[['Facility_or_Department', 'label']].head(n=20).tail(n=10))\n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    \n",
    "    #df = df.rename(columns={'label': f2})\n",
    "    df = df.merge(df_syn, left_on='label', right_on='label', how='left')\n",
    "    del df['label']\n",
    "    df = df.rename(columns={'value': f2})\n",
    "    \n",
    "    \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_clustered = [f2 for f1,f2 in features_clustered]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(len(features))\n",
    "features = features_raw + [f2 for f1,f2 in features_clustered]\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "labels = yaml.load(open(\"labels.yml\",'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function': ['Aides Compensation\n",
    "prediction_names = []\n",
    "for k,v1 in labels.items():\n",
    "    for v2 in v1:\n",
    "        pn = \"%s__%s\"%(k,v2)\n",
    "        prediction_names.append(pn)\n",
    "        \n",
    "        \n",
    "assert 'Function__Aides Compensation' in prediction_names\n",
    "prediction_names.sort()\n",
    "prediction_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate counts"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for f2 in features_clustered:\n",
    "    #print(f2)\n",
    "    df[f2] = df[f2].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[features_raw].loc[134338].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[features_clustered].loc[134338].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_joined(df, features_chosen):\n",
    "    return df[features_chosen].fillna('').apply(lambda x: \"~\".join([y.replace(' ','').replace('\"','') for y in x]), axis=1)\n",
    "    \n",
    "# df['joined'] = calc_joined(df, features_raw)\n",
    "df['joined'] = calc_joined(df, features_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could calculate stats on *all* df instead of just non-holdout\n",
    "# but need this so that predictions.index = df_feat2.index later\n",
    "# stats = df['joined'].value_counts()\n",
    "stats = df['joined'][~df['is_holdout']].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "s2 = stats.copy().reset_index()\n",
    "s2 = s2.merge(df.loc[ df['is_holdout'], ['joined', 'Function']], left_on='index', right_on='joined', how='left')\n",
    "s2 = s2.rename(columns={'Function': 'in_ho'})\n",
    "s2 = s2.merge(df.loc[~df['is_holdout'], ['joined', 'Function']], left_on='index', right_on='joined', how='left')\n",
    "s2 = s2.rename(columns={'Function': 'in_nho'})\n",
    "s2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.sort_values(ascending=False).head(n=15).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=stats.index[10]\n",
    "k1, stats.index.get_loc(k1),1 #df.loc[k1, 'joined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(x=range(stats.shape[0]), height=stats.values)\n",
    "# n_pts = 500000\n",
    "# plt.bar(x=range(n_pts), height=stats.iloc[:n_pts])\n",
    "plt.plot(stats.sort_values(ascending=False).values.cumsum())\n",
    "plt.title(\"%s, %s\"%(stats.values.sum(), stats.shape[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = stats.sort_values(ascending=False).reset_index().loc[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['joined']==k1].shape, df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['joined']==k1]['Function'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The 1st version turned out to have indeces not in stats.index .. weird\n",
    "# prob_fn = 'data_out/t1_probabilities_function.pkl'\n",
    "\n",
    "# Fixing the above in the 2nd version\n",
    "# prob_fn = 'data_out/t1_probabilities_function_v2.pkl'\n",
    "\n",
    "# Set \".sort()\" on features so that they're replicable\n",
    "# prob_fn = 'data_out/t1_probabilities_function_v3.pkl'\n",
    "\n",
    "# Calculate for all targets, not only Functions\n",
    "# prob_fn = 'data_out/t1_probabilities_function_v4.pkl'\n",
    "\n",
    "# raw + clustered features\n",
    "#prob_fn = 'data_out/t1_probabilities_function_v5.pkl'\n",
    "\n",
    "# only clustered features\n",
    "prob_fn = 'data_out/t1_probabilities_function_v6.pkl'\n",
    "\n",
    "os.path.exists(prob_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(prob_fn):\n",
    "    print(\"Loading from file %s\"%prob_fn)\n",
    "    probabilities = pd.read_pickle(prob_fn)\n",
    "else:\n",
    "    probabilities = pd.DataFrame(\n",
    "        np.zeros(shape=(len(prediction_names), stats.shape[0])),\n",
    "        columns=stats.index,\n",
    "        index=prediction_names\n",
    "    )\n",
    "    #probabilities.head(n=2)\n",
    "    \n",
    "    # k1 = stats.index[0]\n",
    "    # probabilities[k1].update(train[train['joined']==k1]['Function'].value_counts())\n",
    "    # probabilities[k1]\n",
    "\n",
    "    n = len(stats.index)\n",
    "    dependents = list(labels.keys())\n",
    "    dependents.sort()\n",
    "    \n",
    "    n = len(dependents)\n",
    "    for i,k2 in enumerate(dependents):\n",
    "        print(\"%s .. %s: %s / %s\"%(time.ctime(), k2, i+1, n))\n",
    "        # important to filter for \"not holdout\"\n",
    "        counts = df[~df['is_holdout']].groupby(['joined']).apply(lambda x: x[k2].value_counts().add_prefix('%s__'%k2)).unstack(0)\n",
    "        probabilities.update(counts)\n",
    "\n",
    "    # save\n",
    "    probabilities.to_pickle(prob_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities.head().values.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since NO_LABEL is replaced with NaN, need this\n",
    "for dependent in labels.keys():\n",
    "    target_sub = [x for x in probabilities.index if x.startswith(\"%s__\"%dependent)]\n",
    "    probabilities.loc['%s__NO_LABEL'%dependent, probabilities.loc[target_sub].sum(axis=0)==0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities.shape, probabilities[pd.isnull(probabilities).all(axis=1)].shape, probabilities.loc[:,probabilities.sum(axis=0)==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ~pd.isnull(probabilities).any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probabilities.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k1 = stats.index[1]\n",
    "# probabilities[k1], (probabilities / probabilities.sum(axis=0))[k1]\n",
    "\n",
    "for k1 in labels.keys():\n",
    "    sub_index = [x for x in probabilities.index if x.startswith(\"%s__\"%k1)]\n",
    "    probabilities.loc[sub_index] = probabilities.loc[sub_index] / probabilities.loc[sub_index].sum(axis=0)\n",
    "                                                                        \n",
    "probabilities = probabilities.transpose()\n",
    "probabilities = probabilities.sort_index()\n",
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probabilities.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities.shape, probabilities[pd.isnull(probabilities).all(axis=1)].shape, probabilities[probabilities.sum(axis=1)==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(stats.index) == set(probabilities.index)\n",
    "# len(set(stats.index) - set(probabilities.index))\n",
    "assert len(set(stats.index) - set(probabilities.index)) >= 0\n",
    "assert len(set(probabilities.index) - set(stats.index)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring back original set of columns\n",
    "These are the fields that got joined with ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_chosen = features_clustered\n",
    "df_feat = df[features_chosen+['joined', 'is_holdout']].copy()\n",
    "df_feat.loc[:,features_chosen] = df_feat[features_chosen].apply(lambda x: pd.factorize(x)[0], axis=0)\n",
    "df_feat[features_chosen] = df_feat[features_chosen] + 1 # +1 for the -1 introduced by pd.factorize (keras Embedding supports [0,N) )    \n",
    "df_feat['duplicated'] = df_feat.duplicated(['joined'])\n",
    "df_feat2 = df_feat[~df_feat['is_holdout'] & ~df_feat.duplicated(['joined'])].set_index('joined').sort_index()[features_chosen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat2.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[features_chosen+['joined']].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(set(probabilities.index) - set(df_feat2.index))[:5]\n",
    "# list(set(df_feat2.index) - set(probabilities.index))[:5]\n",
    "\n",
    "k1 = '~RGNGOB~CONVERSIONCHARTERSCHOOLS~~~EMPLOYEEBENEFITS~~~~PurchasedServices~~~~'\n",
    "# k1 in stats.index\n",
    "# k1 in df_feat2.index\n",
    "df_feat[['is_holdout','duplicated','joined']][df_feat['joined']==k1]\n",
    "# df['joined'][df['joined']==k1].shape\n",
    "# k1 in df['joined'].value_counts().index\n",
    "# stats[k1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(probabilities.index) == set(df_feat2.index)\n",
    "# len(set(probabilities.index)), len(set(df_feat2.index)), len(set(probabilities.index) - set(df_feat2.index))\n",
    "assert len(set(probabilities.index) - set(df_feat2.index)) == 0\n",
    "# len(set(df_feat2.index) - set(probabilities.index))\n",
    "assert len(set(df_feat2.index) - set(probabilities.index)) >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# append \"set_index\" as recommended in pandas github issue 7632\n",
    "# https://github.com/pandas-dev/pandas/issues/7632#issuecomment-316806258\n",
    "# prob2 = probabilities.merge(vocabulary, left_index=True, right_on='joined', how='left').set_index('joined')\n",
    "prob2 = probabilities.merge(df_feat2, left_index=True, right_index=True, how='left') # .set_index('joined')\n",
    "probabilities.shape, prob2.shape # , prob2.head(n=2), prob2.head(n=2).index # , train.loc[70455]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob2[features_chosen].sort_index().head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob3 = prob2[features_chosen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ~pd.isnull(prob3).any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob3.max().max(), prob3.min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob3.shape, probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = df_feat[features_chosen].max(axis=0) + 1 # +1 for the 0\n",
    "pd.DataFrame({'all': vocab_size, 'non-holdout': prob3.max(axis=0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert probabilities.max().max()==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, prob3.shape, probabilities.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split train/test on non-holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = prob3\n",
    "y = probabilities # .fillna(0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras embedding + Dense/LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make array of features\n",
    "x_train = [x_train[f].values for f in vocab_size.index]\n",
    "x_test  = [x_test [f].values for f in vocab_size.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_keys = labels.keys()\n",
    "label_keys = list(label_keys)\n",
    "label_keys.sort()\n",
    "y_train = [y_train[[x for x in prediction_names if x.startswith(\"%s__\"%f)]].values for f in label_keys]\n",
    "y_test  = [y_test [[x for x in prediction_names if x.startswith(\"%s__\"%f)]].values for f in label_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train), y_train[0].shape, y_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dense, Flatten, LSTM, Input, Concatenate, Add, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "\n",
    "# vocab_size = stats.shape[0]\n",
    "\n",
    "# inputs = [Input(shape=(prob3.shape[1],)) for f in vocab_size.index]\n",
    "inputs = {f: Input(shape=(1,), name=f) for f in vocab_size.index}\n",
    "\n",
    "# embeddings = [Embedding(vocab_size[f], embedding_dim, input_length=prob3.shape[1]) for f in vocab_size.index]\n",
    "\n",
    "if True:\n",
    "    embedding_dim = 3 # 12 # 2 # 64 # FIXME\n",
    "    embeddings = [Embedding(vocab_size[f], embedding_dim, input_length=1)(inputs[f]) for f in vocab_size.index]\n",
    "else:\n",
    "    embeddings = [Embedding(vocab_size[f], max(3, vocab_size[f]//15//10), input_length=1)(inputs[f]) for f in vocab_size.index]\n",
    "\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, input_length, embedding_dim), where None is the batch dimension.\n",
    "\n",
    "x1 = Concatenate()(embeddings)\n",
    "\n",
    "x1 = Flatten()(x1)\n",
    "#x1 = Dense( 500, activation='relu')(x1)\n",
    "# x1 = Dense(  50, activation='relu')(x1)\n",
    "\n",
    "# x1 = Dense(  50, activation='relu')(x1)\n",
    "# x1 = Dense(  50, activation='relu')(x1)\n",
    "\n",
    "x1 = Dense( 50, activation='relu')(x1)\n",
    "x1 = Dense( 50, activation='relu')(x1)\n",
    "\n",
    "o1 = {dependent: Dense(50, activation = 'relu', name=\"%s_d1\"%dependent)(x1) for dependent in label_keys}\n",
    "o1 = {dependent: Dense(50, activation = 'relu', name=\"%s_d2\"%dependent)(o1[dependent]) for dependent in label_keys}\n",
    "\n",
    "outputs = [Dense(len(labels[dependent]), activation = 'softmax', name=\"%s_out\"%dependent)(o1[dependent]) for dependent in label_keys]\n",
    "\n",
    "inputs = [inputs[f] for f in vocab_size.index]\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def multi_multiclass_logloss(y_true, y_pred):\n",
    "    # when statring to use Function and others, use this\n",
    "    # return K.mean(-1*K.mean(K.batch_dot(y_true, K.log(y_pred)), axis=-1), axis=-1)\n",
    "    # _epsilon = K.epsilon() * K.ones_like(y_true)\n",
    "    y_pred2 = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    y_true2 = K.clip(y_true, K.epsilon(), 1 - K.epsilon())\n",
    "    # output = -1*K.mean(K.batch_dot(K.transpose(y_true2), K.log(y_pred2), axes=[0,1]), axis=-1)\n",
    "    output = -1*K.squeeze(K.batch_dot(K.transpose(y_true2), K.log(y_pred2), axes=[0,1]), axis=-1)\n",
    "    return output\n",
    "\n",
    "from keras.losses import mean_squared_error, categorical_crossentropy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test K.batch_dot\n",
    "# Need to specify axes due to issue\n",
    "# https://github.com/keras-team/keras/issues/9847\n",
    "deno = 3#9\n",
    "# x_batch = K.ones(shape=(4, deno))/deno\n",
    "# y_batch = K.ones(shape=(4, deno))/deno\n",
    "# x_batch = K.variable(np.array([[1,0,0],[0,1,0],[0,0,1],[0,0,1]]))\n",
    "x_batch = K.variable(np.array([[.4,.3,.3],[.3,.4,.3],[.3,.4,.3],[.4,.3,.3]]))\n",
    "# x_batch = K.variable(np.ones(shape=(4,deno))/deno)\n",
    "y_batch = x_batch\n",
    "# xy_batch_dot = K.batch_dot(K.transpose(x_batch), y_batch, axes=[0, 1])\n",
    "test_1 = multi_multiclass_logloss(x_batch, y_batch)\n",
    "test_2 = mean_squared_error(x_batch, y_batch+.1)\n",
    "test_3 = categorical_crossentropy(x_batch, y_batch+.1)\n",
    "# K.int_shape(test_1), K.eval(test_1), K.eval(test_2), \n",
    "K.eval(test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[-1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile('rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "#model.compile('rmsprop', loss=multi_multiclass_logloss, metrics=['acc'])\n",
    "\n",
    "# from keras.utils import to_categorical\n",
    "# y_binary = to_categorical(np.argmax(y_train.values, axis=1))\n",
    "# y_binary = np.argmax(y_train.values, axis=1).squeeze()\n",
    "\n",
    "model.fit(\n",
    "    # pd.get_dummies(train3['x'].values),\n",
    "    # # train2[list(set(train2.columns) - set(['joined']))],\n",
    "    # train3['y'].values,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32*32, # 32, # FIXME\n",
    "    epochs=300,\n",
    "    verbose=2,\n",
    "    validation_split = 0.2,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## argmax accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "my_score = np.zeros(y_test.shape[0], dtype='uint8')\n",
    "# y_pred, sum_pred = model.predict([x_test[f].values for f in vocab_size.index])\n",
    "y_pred = model.predict(x_test)\n",
    "for i in range(y_test.shape[0]):\n",
    "    v1 = y_test.iloc[i].idxmax()\n",
    "    v2 = probabilities.columns[np.argmax(y_pred[i])]\n",
    "    my_score[i] = 1 if (v1 == v2) else 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sum(my_score), my_score.shape[0], sum(my_score)*100 // my_score.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(min(10,probabilities.shape[1])):\n",
    "    n_show = 1000\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred2 = y_pred[0]\n",
    "    y_test2 = y_test[0]\n",
    "\n",
    "    plt.figure(figsize=(20,3))\n",
    "    plt.plot(y_pred2[:n_show,i], label='pred')\n",
    "    #plt.plot(sum_pred, label='sum_pred', alpha=0.2)\n",
    "    plt.plot(y_test2[:n_show,i], '.', label='actual')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(probabilities.columns[i])\n",
    "    \n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([-.1,1.1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0][0,:].sum(), y_pred[0][0,:].sum() # , y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## temporal comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = {label_keys[i]: y_pred[i] for i in range(len(label_keys))}\n",
    "\n",
    "k2 = 'Function'\n",
    "y_pred2 = y_pred[k2]\n",
    "y_test2 = y_test[0]\n",
    "for i in range(15):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.bar(x=range(y_pred2.shape[1]), height=y_test2[i])\n",
    "    plt.title('%s. actual, argmax=%s'%(i,np.argmax(y_test2[i])))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([-.1,1.1])\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.bar(x=range(y_pred2.shape[1]), height=y_pred2[i])\n",
    "    plt.title('%s. prediction, argmax=%s'%(i,np.argmax(y_pred2[i])))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([-.1,1.1])\n",
    "    \n",
    "    # plt.title(y_test.index[i])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=6\n",
    "y_test[0][i,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ho = df_feat[features_chosen][~df['is_holdout']].head()\n",
    "x_ho  = [x_ho [f].values for f in vocab_size.index]\n",
    "y_ho = model.predict(x_ho)\n",
    "df_submit = pd.DataFrame(np.concatenate(y_ho, axis=1), columns=prediction_names)\n",
    "df_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ho = df_feat[features_chosen][ df['is_holdout']]\n",
    "x_ho  = [x_ho [f].values for f in vocab_size.index]\n",
    "y_ho = model.predict(x_ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_ho), y_ho[0].shape, y_ho[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho  = df[ df['is_holdout']]\n",
    "df_nho = df[~df['is_holdout']]\n",
    "df_ho.shape, df_ho[df_ho['joined'].isin(df_nho['joined'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho[features_chosen].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho[features_chosen].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ho['joined'].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nho[df_nho['Sub_Object_Description']==\"Line Item that is paid with Campus' money\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_holdout'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame(np.concatenate(y_ho, axis=1), columns=prediction_names, index=df_feat[ df['is_holdout']].index)\n",
    "df_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(df_submit['Use__NO_LABEL'].sort_values().values)\n",
    "plt.plot(df_submit['Operating_Status__NO_LABEL'].sort_values().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert (df_submit['Operating_Status__NO_LABEL']==0).all()\n",
    "assert (df_submit['Operating_Status__NO_LABEL']<.000001).all()\n",
    "del df_submit['Operating_Status__NO_LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'data_out/submission_B_%s.csv'%(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "df_submit.to_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
