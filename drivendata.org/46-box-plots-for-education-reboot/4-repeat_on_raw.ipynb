{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/44544766/ddg#44547144\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_read_csv(fn:str):\n",
    "    x = pd.read_csv(fn, na_values=['NO_LABEL', '(blank)'])\n",
    "    assert not x['Unnamed: 0'].duplicated().any()\n",
    "    x = x.set_index(\"Unnamed: 0\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd_read_csv('data_in/TrainingData.csv')\n",
    "test = pd_read_csv('data_in/TestData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.columns\n",
    "train['Position_Type'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(train.columns).intersection(set(test.columns)) - set(['FTE','Total']))\n",
    "features.sort()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = set(train.columns) - set(test.columns)\n",
    "target = list(target)\n",
    "target.sort()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in target:\n",
    "    test[col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_holdout'] = False\n",
    "test ['is_holdout'] = True\n",
    "df = pd.concat([train,test], axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = list(set(df.columns) - set(features) - set(target))\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df[features].shape, df[target].shape, df[meta].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "labels = yaml.load(open(\"labels.yml\",'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function': ['Aides Compensation\n",
    "prediction_names = []\n",
    "for k,v1 in labels.items():\n",
    "    for v2 in v1:\n",
    "        pn = \"%s__%s\"%(k,v2)\n",
    "        prediction_names.append(pn)\n",
    "        \n",
    "        \n",
    "assert 'Function__Aides Compensation' in prediction_names\n",
    "prediction_names.sort()\n",
    "prediction_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert target to label-like columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in prediction_names: df[p] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v1 in labels.items():\n",
    "    for v2 in v1:\n",
    "        pn = \"%s__%s\"%(k,v2)\n",
    "        # print(pn)\n",
    "        df[pn] = df[k] == v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since NO_LABEL is replaced with NaN, need this\n",
    "for dependent in labels.keys():\n",
    "    target_sub = [x for x in df.columns if x.startswith(\"%s__\"%dependent)]\n",
    "    df.loc[~df[target_sub].any(axis=1), '%s__NO_LABEL'%dependent]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Function', 'Function__Teacher Compensation', 'Function__Substitute Compensation', 'Function__NO_LABEL']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df[pd.isnull(df[prediction_names]).all(axis=1)].shape, df.loc[~df[prediction_names].any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ~pd.isnull(df[prediction_names]).any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[prediction_names] = df[prediction_names].astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.ctime())\n",
    "df2 = df[features].apply(lambda x: pd.factorize(x)[0], axis=0)\n",
    "df2 = df2 + 1 # +1 for the -1 (keras Embedding supports [0,N) )    \n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.max().max(), df2.min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = df2.max(axis=0) + 1 # +1 for the 0\n",
    "vocab_size = vocab_size.sort_index()\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df[prediction_names].max().max()==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df2[~df['is_holdout']]\n",
    "y = df[prediction_names][~df['is_holdout']] # .fillna(0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras embedding + Dense/LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make array of features\n",
    "x_train = [x_train[f].values for f in vocab_size.index]\n",
    "x_test  = [x_test [f].values for f in vocab_size.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_keys = labels.keys()\n",
    "label_keys = list(label_keys)\n",
    "label_keys.sort()\n",
    "y_train = [y_train[[x for x in prediction_names if x.startswith(\"%s__\"%f)]].values for f in label_keys]\n",
    "y_test  = [y_test [[x for x in prediction_names if x.startswith(\"%s__\"%f)]].values for f in label_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train), y_train[0].shape, y_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dense, Flatten, LSTM, Input, Concatenate, Add, Lambda\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "\n",
    "# vocab_size = stats.shape[0]\n",
    "\n",
    "# inputs = [Input(shape=(prob3.shape[1],)) for f in vocab_size.index]\n",
    "inputs = {f: Input(shape=(1,), name=f) for f in vocab_size.index}\n",
    "\n",
    "# embeddings = [Embedding(vocab_size[f], embedding_dim, input_length=prob3.shape[1]) for f in vocab_size.index]\n",
    "\n",
    "if True:\n",
    "    embedding_dim = 3 # 12 # 2 # 64 # FIXME\n",
    "    embeddings = [Embedding(vocab_size[f], embedding_dim, input_length=1)(inputs[f]) for f in vocab_size.index]\n",
    "else:\n",
    "    embeddings = [Embedding(vocab_size[f], max(3, vocab_size[f]//15//10), input_length=1)(inputs[f]) for f in vocab_size.index]\n",
    "\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, input_length, embedding_dim), where None is the batch dimension.\n",
    "\n",
    "x1 = Concatenate()(embeddings)\n",
    "\n",
    "x1 = Flatten()(x1)\n",
    "#x1 = Dense( 500, activation='relu')(x1)\n",
    "# x1 = Dense(  50, activation='relu')(x1)\n",
    "\n",
    "# x1 = Dense(  50, activation='relu')(x1)\n",
    "# x1 = Dense(  50, activation='relu')(x1)\n",
    "\n",
    "x1 = Dense( 50, activation='relu')(x1)\n",
    "x1 = Dense( 50, activation='relu')(x1)\n",
    "\n",
    "o1 = {dependent: Dense(50, activation = 'relu', name=\"%s_d1\"%dependent)(x1) for dependent in label_keys}\n",
    "o1 = {dependent: Dense(50, activation = 'relu', name=\"%s_d2\"%dependent)(o1[dependent]) for dependent in label_keys}\n",
    "\n",
    "outputs = [Dense(len(labels[dependent]), activation = 'softmax', name=\"%s_out\"%dependent)(o1[dependent]) for dependent in label_keys]\n",
    "\n",
    "inputs = [inputs[f] for f in vocab_size.index]\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_multiclass_logloss(y_true, y_pred):\n",
    "    # when statring to use Function and others, use this\n",
    "    # return K.mean(-1*K.mean(K.batch_dot(y_true, K.log(y_pred)), axis=-1), axis=-1)\n",
    "    # _epsilon = K.epsilon() * K.ones_like(y_true)\n",
    "    y_pred2 = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    output = -1*K.mean(K.batch_dot(K.transpose(y_true), K.log(y_pred2), axes=[0,1]), axis=-1)\n",
    "    return output\n",
    "\n",
    "# model.compile('rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.compile('rmsprop', loss=multi_multiclass_logloss, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test K.batch_dot\n",
    "# Need to specify axes due to issue\n",
    "# https://github.com/keras-team/keras/issues/9847\n",
    "x_batch = K.ones(shape=(32, 37))\n",
    "y_batch = K.ones(shape=(32, 37))\n",
    "# xy_batch_dot = K.batch_dot(K.transpose(x_batch), y_batch, axes=[0, 1])\n",
    "xy_batch_dot = multi_multiclass_logloss(x_batch, y_batch)\n",
    "K.int_shape(xy_batch_dot), K.eval(xy_batch_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from keras.utils import to_categorical\n",
    "# y_binary = to_categorical(np.argmax(y_train.values, axis=1))\n",
    "# y_binary = np.argmax(y_train.values, axis=1).squeeze()\n",
    "\n",
    "model.fit(\n",
    "    # pd.get_dummies(train3['x'].values),\n",
    "    # # train2[list(set(train2.columns) - set(['joined']))],\n",
    "    # train3['y'].values,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32, #32*32, # 32, # FIXME\n",
    "    epochs=300,\n",
    "    verbose=2,\n",
    "    validation_split = 0.2,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## argmax accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_score = np.zeros(y_test.shape[0], dtype='uint8')\n",
    "# y_pred, sum_pred = model.predict([x_test[f].values for f in vocab_size.index])\n",
    "y_pred = model.predict([x_test[f].values for f in vocab_size.index])\n",
    "for i in range(y_test.shape[0]):\n",
    "    v1 = y_test.iloc[i].idxmax()\n",
    "    v2 = probabilities.columns[np.argmax(y_pred[i])]\n",
    "    my_score[i] = 1 if (v1 == v2) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(my_score), my_score.shape[0], sum(my_score)*100 // my_score.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(min(10,probabilities.shape[1])):\n",
    "    n_show = 1000\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred2 = y_pred[0]\n",
    "    y_test2 = y_test[0]\n",
    "\n",
    "    plt.figure(figsize=(20,3))\n",
    "    plt.plot(y_pred2[:n_show,i], label='pred')\n",
    "    #plt.plot(sum_pred, label='sum_pred', alpha=0.2)\n",
    "    plt.plot(y_test2[:n_show,i], '.', label='actual')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(probabilities.columns[i])\n",
    "    \n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([-.1,1.1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[0].sum(), y_pred[0].sum() # , y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## temporal comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = {label_keys[i]: y_pred[i] for i in range(len(label_keys))}\n",
    "\n",
    "k2 = 'Function'\n",
    "y_pred2 = y_pred[k2]\n",
    "y_test2 = y_test[0]\n",
    "for i in range(15):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.bar(x=range(y_pred2.shape[1]), height=y_test2[i])\n",
    "    plt.title('%s. actual, argmax=%s'%(i,np.argmax(y_test2[i])))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([-.1,1.1])\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.bar(x=range(y_pred2.shape[1]), height=y_pred2[i])\n",
    "    plt.title('%s. prediction, argmax=%s'%(i,np.argmax(y_pred2[i])))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([-.1,1.1])\n",
    "    \n",
    "    # plt.title(y_test.index[i])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=6\n",
    "y_test.iloc[i].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.shape)\n",
    "test['joined'] = calc_joined(test)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape, test[test['joined'].isin(train['joined'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[features].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[features].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['joined'].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['Sub_Object_Description']==\"Line Item that is paid with Campus' money\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=None, random_state=0, verbose=2, n_jobs=-1)\n",
    "\n",
    "\n",
    "regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(prob3.columns, regr.feature_importances_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(regr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred_rf = regr.predict(x_test[:3]) # .round(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred_rf.sum(axis=1), y_pred_rf[0], y_test[:3].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
