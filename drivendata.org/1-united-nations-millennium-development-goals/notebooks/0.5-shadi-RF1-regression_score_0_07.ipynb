{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as 0.4 with linear regression, but here using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import *\n",
    "train = load_raw()\n",
    "cols = imply_columns(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not train['Unnamed: 0'].duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.isnull(train[cols['features']]).sum(axis=1).sort_values(ascending=True).head(n=20)\n",
    "train.shape[0], len(np.where(pd.isnull(train[cols['features']]).sum(axis=1) < 5)[0])\n",
    "# train.iloc[0,'1972 [YR1972]']\n",
    "# pd.isnull(train.loc[0,'1972 [YR1972]'])\n",
    "# train.head()\n",
    "# train.loc[131876]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_submit = pd.read_csv('data/raw/submission.csv').set_index('Unnamed: 0')\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(train.loc[df_submit.index]['Country Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train.loc[df_submit.index]['Series Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_inds = list(set(df_submit.index))\n",
    "submit_inds.sort()\n",
    "submit_inds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess data to backfill nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rename = {x: x[6:-1] for x in cols['features']}\n",
    "train.rename(columns=my_rename, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols['features'] = list(my_rename.values())\n",
    "cols['features'].sort()\n",
    "cols['features'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide to long format so that years are an index along the rows\n",
    "train = pd.wide_to_long(train.reset_index(), [\"YR\"], i=\"Unnamed: 0\", j=\"year\").reset_index(level='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename YR to \"value\"\n",
    "train.rename(columns={'YR': 'value'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['year'] = train['year'].apply(lambda x: int(x))\n",
    "train['year'].head().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot again just to confirm that wide-to-long worked\n",
    "country = 'Kenya' # 'Poland'\n",
    "series = 'Net taxes on products (current LCU)'\n",
    "subtrain = train[(train['Country Name']==country) & (train['Series Name']==series)]\n",
    "subtrain = subtrain.set_index('year')\n",
    "subtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtrain['value'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(subtrain['value'])\n",
    "plt.title(\"%s: %s\"%(country, series))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group and backfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "df = pd.DataFrame([[np.nan, 2, np.nan, 0, 2, 2],\n",
    "                   [3, 4, np.nan, 1, 1, 2],\n",
    "                   [np.nan, np.nan, np.nan, 5, 1, 3],\n",
    "                   [np.nan, 3, np.nan, 4, 1, 4],\n",
    "                  ],\n",
    "                  columns=list('ABCDEF'))\n",
    "df['B'] = df.sort_values('F', ascending=True).groupby(['E'])['B'].fillna(method='ffill')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nan_before = pd.isnull(train['value']).sum()\n",
    "print('before: number of nan: %s'%n_nan_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# around 15 seconds\n",
    "print(time.ctime(), 'start group')\n",
    "train2 = train.copy()\n",
    "train2 = train2.sort_values(['Country Name', 'Series Code', 'year'], ascending=True)\n",
    "t_group = train2.groupby(['Country Name', 'Series Code'])\n",
    "print(time.ctime(), 'end group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# around 1 minute\n",
    "print(time.ctime(), 'start fill')\n",
    "train2['value'] = t_group['value'].fillna(method='ffill')\n",
    "print(time.ctime(), 'end fill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nan_after = pd.isnull(train2['value']).sum()\n",
    "print('after: number of nan: %s'%n_nan_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill remaining nan with bfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group again and backfill this time ... this is kind of cheating\n",
    "# ~ 1 minute\n",
    "print(time.ctime(), 'start fill')\n",
    "t_group = train2.groupby(['Country Name', 'Series Code'])\n",
    "train2['value'] = t_group['value'].fillna(method='bfill')\n",
    "print(time.ctime(), 'end fill')\n",
    "n_nan_after2 = pd.isnull(train2['value']).sum()\n",
    "print('after: number of nan: %s'%n_nan_after2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.reset_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pivot table\n",
    "\n",
    "- temporal dimension: year\n",
    "- spatial dimension: country/series pair\n",
    "\n",
    "This results in a transpose of the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = train2.reset_index().pivot(index='year', columns='Unnamed: 0', values='value')\n",
    "train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3[[16,559]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strike>multi-variate OLS</strike> Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# Method 1: target is a single country/series pair, features are all else\n",
    "# diabetes_X = diabetes_0[list(set(diabetes_0.columns) - set([index]))].values\n",
    "# diabetes_y = train3[index].values\n",
    "\n",
    "# Method 2: features are lagged data (drop 1st row since cannot predict)\n",
    "# Filter for last 7 points\n",
    "n_shift=1\n",
    "n_last = 7\n",
    "n_focus = 10\n",
    "diabetes_X = train3[submit_inds].shift(n_shift).iloc[n_shift:].tail(n_last)\n",
    "diabetes_y = train3[submit_inds].iloc[n_shift:, :n_focus].tail(n_last)\n",
    "\n",
    "# prepare append year to features\n",
    "year1 = diabetes_X.reset_index()[['year']].values\n",
    "print(year1.squeeze())\n",
    "\n",
    "# to avoid multi-colinearity, reduce features\n",
    "\n",
    "# Method 1: select top n features\n",
    "# http://scikit-learn.org/stable/auto_examples/plot_compare_reduction.html#sphx-glr-auto-examples-plot-compare-reduction-py\n",
    "# This beats the performance of the PCA\n",
    "# mdl = SelectKBest(f_regression, k=40) # 20 and 40 are good\n",
    "# diabetes_X = mdl.fit_transform(diabetes_X, diabetes_y)\n",
    "\n",
    "# Method 2: PCA to reduce features\n",
    "# # mdl = PCA(n_components='mle') # TODO report bug\n",
    "# # mdl = PCA(n_components='mle', svd_solver = 'full') # mle not supported for n_samples < n_features\n",
    "# mdl = PCA(n_components=20, svd_solver = 'full') # 20 is too small resulting in too large error\n",
    "# diabetes_X = mdl.fit_transform(diabetes_X)\n",
    "\n",
    "# execute append year to features\n",
    "print('diabetes_X.shape, year1.shape', diabetes_X.shape, year1.shape)\n",
    "diabetes_X = np.concatenate([diabetes_X, year1], axis=1)\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "n_test = 2 # FIXME: 0 2\n",
    "if n_test > 0:\n",
    "    diabetes_X_train = diabetes_X[:-1*n_test]\n",
    "    diabetes_X_test = diabetes_X[-1*n_test:]\n",
    "else:\n",
    "    diabetes_X_train = diabetes_X\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "if n_test > 0:\n",
    "    diabetes_y_train = diabetes_y.iloc[:-1*n_test]\n",
    "    diabetes_y_test = diabetes_y.iloc[-1*n_test:]\n",
    "else:\n",
    "    diabetes_y_train = diabetes_y\n",
    "\n",
    "# Create linear regression object\n",
    "# regr = linear_model.LinearRegression()\n",
    "regr = ensemble.RandomForestRegressor(n_estimators=100, min_samples_split=4, verbose=0, n_jobs=-1)\n",
    "\n",
    "# Train the model using the training sets\n",
    "print('fit', diabetes_X_train.shape, diabetes_y_train.shape)\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def year2col(x):\n",
    "    return \"%.0f [YR%.0f]\"%(x, x)\n",
    "\n",
    "year2col(2008), year2col(2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_submit2 = df_submit.copy()\n",
    "\n",
    "# df_submit2[year2col(2008)] = np.nan\n",
    "df_submit2[year2col(2009)] = np.nan\n",
    "df_submit2[year2col(2010)] = np.nan\n",
    "df_submit2[year2col(2011)] = np.nan\n",
    "# df_submit2[year2col(2012)] = np.nan\n",
    "\n",
    "if n_test > 0:\n",
    "    # re-predict since first test point\n",
    "    n_pred2 = 1\n",
    "    diabetes_y_pred2 = diabetes_y_test.iloc[:n_pred2, :n_focus]\n",
    "    year2 = diabetes_y_test.reset_index()[['year']].iloc[:n_pred2]\n",
    "else:\n",
    "    # take last point as starting point of predictions\n",
    "    # (no need to drop year column since using y_train and not X_train)\n",
    "    diabetes_y_pred2 = diabetes_y_train[-1:]\n",
    "    year2 = train3.reset_index()[['year']][n_shift:][-1:]\n",
    "\n",
    "print('base year', year2)\n",
    "for i_pred2 in range(5):\n",
    "    diabetes_y_pred2 = np.concatenate([diabetes_y_pred2, year2-1+i_pred2], axis=1)\n",
    "    diabetes_y_pred2 = regr.predict(diabetes_y_pred2)\n",
    "    print('set year', year2.values[0]+1+i_pred2)\n",
    "    df_submit2.loc[:,year2col(year2.values[0]+1+i_pred2)] = diabetes_y_pred2.transpose()\n",
    "\n",
    "\n",
    "for index in submit_inds[:10]: #[559, 618]:\n",
    "    # print(train3.index[1:][:-1*n_test].shape, diabetes_y_train.shape, diabetes_y_train[:,submit_inds.index(index)].squeeze().shape)\n",
    "    \n",
    "    # Plot outputs\n",
    "    if n_test > 0:\n",
    "        plt.plot(diabetes_y_train[index], '.', color='black')\n",
    "        plt.plot(diabetes_y_test[index], '.', color='green', alpha=0.5)\n",
    "        plt.scatter(train3.index[n_shift:][-1*n_test:], diabetes_y_pred[:,submit_inds.index(index)].squeeze(), color='red', alpha=0.5)\n",
    "    else:\n",
    "        plt.scatter(train3.index[n_shift:], diabetes_y_train[:,submit_inds.index(index)].squeeze(), color='black')\n",
    "        \n",
    "    # print(year2)\n",
    "    for i_pred2 in range(5):\n",
    "        plt.scatter(year2+1+i_pred2, df_submit2.loc[index, year2col(year2.values[0]+1+i_pred2)].squeeze(), color='orange', alpha=0.5)\n",
    "\n",
    "    plt.title(index)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[1,2,3,4,5]\n",
    "x[:-1], x[-1:], x[:-0], x[-0:], x[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit3 = df_submit2[['2008 [YR2008]', '2012 [YR2012]']].copy()\n",
    "df_submit3 = df_submit3.fillna(value=0)\n",
    "df_submit3 = df_submit3.reset_index()[['Unnamed: 0', '2008 [YR2008]', '2012 [YR2012]']]\n",
    "df_submit3.rename(columns={'Unnamed: 0': ''}, inplace=True)\n",
    "fn1, fn2 = make_submission(df_submit3)\n",
    "fn1, fn2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
