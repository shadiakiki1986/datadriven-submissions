{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change from 3.0\n",
    "\n",
    "- append diff of features for seasonality\n",
    "\n",
    "For reference, check https://github.com/drivendata/benchmarks/blob/master/dengue-benchmark-statsmodels.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.build_features import load_raw\n",
    "\n",
    "df_all = load_raw()\n",
    "\n",
    "# replace with 0.2 output\n",
    "df_all['labels_train'] = pd.read_pickle('data/processed/is_epidemic.pkl')\n",
    "\n",
    "df_all.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['features_train'].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['labels_train'].head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ['features_train', 'features_test']:\n",
    "    df_all[k] = df_all[k].groupby('city').apply(lambda group: group.fillna(method='ffill'))\n",
    "    assert ~(pd.isnull(df_all[k]).any().any())\n",
    "    print(df_all[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replace with seasonality decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.statsmodels.org/stable/generated/statsmodels.tsa.seasonal.seasonal_decompose.html#statsmodels.tsa.seasonal.seasonal_decompose\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "def deseason(kkk):\n",
    "    # kkk: 'features_train'\n",
    "    selected_features = list(set(df_all[kkk].columns) - set(['year', 'weekofyear']))\n",
    "\n",
    "    df_train = []\n",
    "    for city in ['sj','iq']:\n",
    "        df_interim = []\n",
    "        for jjj in selected_features:\n",
    "            res0 = df_all[kkk].loc[city, jjj]\n",
    "            res1 = res0 - res0.mean(axis=0)\n",
    "            res2 = seasonal_decompose(res1, freq=52, two_sided=False)\n",
    "            res2 = pd.DataFrame({\n",
    "                #'original': res0,\n",
    "                'trend': res2.trend, \n",
    "                'seasonal': res2.seasonal, \n",
    "                'resid': res2.resid\n",
    "            })\n",
    "\n",
    "            res2.plot()\n",
    "            plt.title(\"%s: %s\"%(city,jjj))\n",
    "            plt.show()\n",
    "\n",
    "            res2['original'] = res0\n",
    "            res2 = res2.rename(columns={\n",
    "                'original': \"%s_original\"%jjj,\n",
    "                'trend': \"%s_trend\"%jjj,\n",
    "                'seasonal': \"%s_seasonal\"%jjj,\n",
    "                'resid': \"%s_resid\"%jjj,\n",
    "            })\n",
    "\n",
    "            res2['city'] = city\n",
    "\n",
    "            res2 = res2.reset_index().set_index(['city', 'week_start_date'])\n",
    "            df_interim.append(res2)\n",
    "\n",
    "        df_train.append(pd.concat(df_interim, axis=1))\n",
    "\n",
    "    df_train = pd.concat(df_train, axis=0, sort=True)\n",
    "    df_train = df_train[pd.notnull(df_train).all(axis=1)]\n",
    "    \n",
    "    return df_train\n",
    "\n",
    "df_train = deseason('features_train')\n",
    "df_test = deseason('features_test')\n",
    "df_train.groupby('city').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add back weekofyear\n",
    "df_train['weekofyear'] = df_all['features_train']['weekofyear']\n",
    "df_test['weekofyear'] = df_all['features_test']['weekofyear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train.shape, df_all['features_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ~(pd.isnull(df_train).any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn1 = 'data/processed/deseasoned_%s.pkl'\n",
    "for kkk in ['train','test']:\n",
    "    import os\n",
    "    fn2 = fn1%kkk\n",
    "    if os.path.exists(fn2):\n",
    "        raise ValueError('file exists: %s'%fn2)\n",
    "        \n",
    "df_train.to_pickle(fn1%'train')\n",
    "df_test.to_pickle(fn1%'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features selected from\n",
    "# https://github.com/drivendata/benchmarks/blob/master/dengue-benchmark-statsmodels.ipynb\n",
    "#selected_features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "#                 'reanalysis_dew_point_temp_k', \n",
    "#                 'station_avg_temp_c', \n",
    "#                 'station_min_temp_c']\n",
    "\n",
    "# all features\n",
    "# selected_features = df_all['features_train'].columns\n",
    "\n",
    "# check no missing\n",
    "# assert len(set(selected_features) - set(df_all['features_train'].columns))==0\n",
    "\n",
    "#################################\n",
    "\n",
    "# all original/trend/seasonal features\n",
    "# selected_features = df_train.columns\n",
    "\n",
    "# only trend + weekofyear\n",
    "import numpy as np\n",
    "selected_features = np.array([x for x in df_train.columns if x.endswith('_trend') or x=='weekofyear'])\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split per city\n",
    "x_train = ( # df_all['features_train']\n",
    "           df_train\n",
    "          .groupby(level='city', as_index=False)\n",
    "          .apply(lambda group: group.head(n=group.shape[0]*3//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          [selected_features]\n",
    "          )\n",
    "x_test = ( # df_all['features_train']\n",
    "            df_train\n",
    "          .groupby(level='city', as_index=False)\n",
    "          .apply(lambda group: group.tail(n=group.shape[0]*1//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          [selected_features]\n",
    "         )\n",
    "y_train = ( # df_all['labels_train']\n",
    "            df_all['labels_train'].loc[df_train.index]\n",
    "          .groupby('city', as_index=False)\n",
    "          .apply(lambda group: group.head(n=group.shape[0]*3//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          # ['total_cases']\n",
    "          ['is_epidemic'].astype('int')\n",
    "         )\n",
    "y_test = ( # df_all['labels_train']\n",
    "            df_all['labels_train'].loc[df_train.index]\n",
    "          .groupby('city', as_index=False)\n",
    "          .apply(lambda group: group.tail(n=group.shape[0]*1//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          #['total_cases']\n",
    "          ['is_epidemic'].astype('int')\n",
    "         )\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.groupby('city').head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.groupby('city').head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_train.reset_index()['city'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # return RandomForestRegressor(n_estimators=100, min_samples_split=5, min_samples_leaf=3)\n",
    "    return RandomForestClassifier(n_estimators=100, min_samples_split=5, min_samples_leaf=3)\n",
    "\n",
    "\n",
    "mod1_sj = create_model()\n",
    "mod1_sj.fit(X = x_train.loc['sj'], y = y_train.loc['sj'])\n",
    "mod1_iq = create_model()\n",
    "mod1_iq.fit(X = x_train.loc['iq'], y = y_train.loc['iq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check feature importances"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# From benchmark\n",
    "#selected_features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "#                 'reanalysis_dew_point_temp_k', \n",
    "#                 'station_avg_temp_c', \n",
    "#                 'station_min_temp_c']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_imp = mod1_sj.feature_importances_\n",
    "#feat_imp.sort()\n",
    "#feat_imp, mod1_sj.feature_importances_, mod1_sj.feature_importances_.argsort(), \n",
    "xxx = mod1_sj.feature_importances_\n",
    "xxx.sort()\n",
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod1_sj.feature_importances_.argsort().astype('int')\n",
    "# selected_features\n",
    "selected_features[mod1_sj.feature_importances_.argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = mod1_iq.feature_importances_\n",
    "xxx.sort()\n",
    "xxx[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[mod1_iq.feature_importances_.argsort()[-15:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## common important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[mod1_sj.feature_importances_.argsort()[-15:]] & selected_features[mod1_iq.feature_importances_.argsort()[-15:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to int since we know the label is integer\n",
    "predictions = (y_test.copy()*0).astype('int')\n",
    "\n",
    "predictions.loc['sj'] = mod1_sj.predict(x_test.loc['sj']).astype(int)\n",
    "predictions.loc['iq'] = mod1_iq.predict(x_test.loc['iq']).astype(int)\n",
    "\n",
    "predictions.loc['sj'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'sj', mod1_sj.score(x_test.loc['sj'], y_test.loc['sj']), 'iq', mod1_iq.score(x_test.loc['iq'], y_test.loc['iq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in ['sj', 'iq']:\n",
    "    plt.plot(y_test.loc[city], label='actual')\n",
    "    plt.plot(predictions.loc[city], label='predicted')\n",
    "    plt.title(city)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-fit on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note avoiding class bias\n",
    "x_retrain = df_all['features_train'][selected_features]\n",
    "y_retrain = df_all['labels_train']['total_cases']\n",
    "\n",
    "mod1_sj = create_model()\n",
    "mod1_sj.fit(X = x_retrain.loc['sj'], y = y_retrain.loc['sj'])\n",
    "mod1_iq = create_model()\n",
    "mod1_iq.fit(X = x_retrain.loc['iq'], y = y_retrain.loc['iq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set in submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['submission'].loc['sj'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to int since we know the label is integer\n",
    "predictions = (df_all['submission'][['total_cases']]\n",
    "               .groupby(level='city', as_index=False)\n",
    "               .apply(lambda group: group.iloc[n_diff:])\n",
    "               .reset_index(level=0, drop=True)\n",
    "               .copy()\n",
    "               *0\n",
    "              ).astype('int')\n",
    "\n",
    "predictions.loc['sj', 'total_cases'] = mod1_sj.predict(df_all['features_test'].loc['sj', selected_features]).astype(int)\n",
    "predictions.loc['iq', 'total_cases'] = mod1_iq.predict(df_all['features_test'].loc['iq', selected_features]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions.groupby(level='city').head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = df_all['submission'].copy()\n",
    "# TODO Will this match indeces properly?\n",
    "# submit['total_cases'] = predictions\n",
    "\n",
    "del submit['total_cases']\n",
    "\n",
    "submit = submit.merge(\n",
    "    predictions,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "submit['total_cases'] = submit['total_cases'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.groupby('city').head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in ['sj','iq']:\n",
    "    plt.plot(submit.loc[city, 'total_cases'].values, label=city)\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.build_features import make_submission"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "make_submission(submit.reset_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
