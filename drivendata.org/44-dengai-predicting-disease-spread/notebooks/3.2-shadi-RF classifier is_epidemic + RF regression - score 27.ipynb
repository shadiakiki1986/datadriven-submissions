{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change from 3.1\n",
    "\n",
    "- change regression to classification\n",
    "\n",
    "For reference, check https://github.com/drivendata/benchmarks/blob/master/dengue-benchmark-statsmodels.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.build_features import load_raw\n",
    "\n",
    "df_all = load_raw()\n",
    "df_all.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['features_train'].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['labels_train'].head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ['features_train', 'features_test']:\n",
    "    df_all[k] = df_all[k].groupby('city').apply(lambda group: group.fillna(method='ffill'))\n",
    "    assert ~(pd.isnull(df_all[k]).any().any())\n",
    "    print(df_all[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## append without seasonality"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_diff = 1\n",
    "for k in ['features_train', 'features_test']:\n",
    "    temp_no = (df_all[k]\n",
    "               .groupby('city', as_index=False)\n",
    "               .apply(lambda group: group.diff(periods=n_diff).iloc[n_diff:])\n",
    "               .reset_index(level=0, drop=True)\n",
    "              )\n",
    "    temp_no.columns = [\"%s_diff\"%x for x in temp_no.columns]\n",
    "    assert ~(pd.isnull(temp_no).any().any())\n",
    "    \n",
    "    temp_yes = (df_all[k]\n",
    "               .groupby('city', as_index=False)\n",
    "               .apply(lambda group: group.iloc[n_diff:])\n",
    "               .reset_index(level=0, drop=True)\n",
    "              )\n",
    "    \n",
    "    df_all[k] = pd.concat([temp_yes, temp_no], axis=1)\n",
    "    print(df_all[k].shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for k in ['features_train', 'features_test']:\n",
    "    assert ~(pd.isnull(df_all[k]).any().any())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# drop n_diff points from labels as well\n",
    "for k in ['labels_train']:\n",
    "    temp_yes = (df_all[k]\n",
    "               .groupby('city', as_index=False)\n",
    "               .apply(lambda group: group.iloc[n_diff:])\n",
    "               .reset_index(level=0, drop=True)\n",
    "              )\n",
    "    \n",
    "    df_all[k] = temp_yes\n",
    "    print(df_all[k].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## features = rolling mean(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_rollingmean(df):\n",
    "    return df.rolling(window=5, center=False, axis=0).mean().fillna(value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all2 = {}\n",
    "for k in df_all.keys():\n",
    "    df_all2[k] = df_all[k].copy()\n",
    "\n",
    "for k in ['features_train', 'features_test']:\n",
    "    df_all2[k] = (df_all2[k]\n",
    "              .groupby(level='city', as_index=False)\n",
    "              .apply(my_rollingmean)\n",
    "              #.reset_index(level=0, drop=True)\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert target to categories\n",
    "\n",
    "- no epidemic\n",
    "- yes epidemic"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_all2['labels_train']['is_epidemic'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME use correlation with a sample signal\n",
    "df_all2['labels_train']['is_epidemic'] = df_all2['labels_train']['total_cases'].apply(lambda x: x >= 20)\n",
    "\n",
    "def require_consecutive(series):\n",
    "    return (\n",
    "        series\n",
    "         .astype('int')\n",
    "         .groupby('city')\n",
    "         # require 4/5 consecutive is_epidemic points\n",
    "         .apply(\n",
    "             lambda group: (\n",
    "                 group.rolling(window=5,center=True)\n",
    "                      .mean()\n",
    "                      .fillna(value=0) > 0.8\n",
    "             ).apply(lambda x: max(x,0)>0)\n",
    "         )\n",
    "    )\n",
    "\n",
    "df_all2['labels_train']['is_epidemic'] = require_consecutive(df_all2['labels_train']['is_epidemic'])\n",
    "# df_all2['labels_train'].groupby(['city','is_epidemic']).head(n=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_all2['labels_train']['is_epidemic'].astype('int').groupby('city').plot()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(df_all2['labels_train']['total_cases'] * df_all2['labels_train']['is_epidemic']).astype('int').groupby('city').plot()\n",
    "plt.legend()\n",
    "plt.title('only epidemic')\n",
    "plt.show()\n",
    "\n",
    "(df_all2['labels_train']['total_cases'] * ~df_all2['labels_train']['is_epidemic']).astype('int').groupby('city').plot()\n",
    "plt.legend()\n",
    "plt.title('non - epidemic')\n",
    "plt.show()\n",
    "\n",
    "(df_all2['labels_train']['total_cases']).astype('int').groupby('city').plot()\n",
    "plt.legend()\n",
    "plt.title('all')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what is the average non-epidemic count?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(df_all2['labels_train']['total_cases'] * ~df_all2['labels_train']['is_epidemic']).astype('int').groupby('city').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target = diff(rolling mean(target))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_all2['labels_train']['diff_cases'] = my_rollingmean(df_all2['labels_train']['total_cases']).diff().fillna(value=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(df_all2['labels_train']['diff_cases'] * df_all2['labels_train']['is_epidemic']).astype('int').groupby('city').plot()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features selected from\n",
    "# https://github.com/drivendata/benchmarks/blob/master/dengue-benchmark-statsmodels.ipynb\n",
    "#selected_features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "#                 'reanalysis_dew_point_temp_k', \n",
    "#                 'station_avg_temp_c', \n",
    "#                 'station_min_temp_c']\n",
    "\n",
    "# all features\n",
    "selected_features = df_all2['features_train'].columns\n",
    "\n",
    "# check no missing\n",
    "assert len(set(selected_features) - set(df_all2['features_train'].columns))==0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all2['features_train'].shape, df_all2['labels_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# note avoiding class bias\n",
    "x_train = (df_all2['features_train']\n",
    "          .groupby(level='city', as_index=False)\n",
    "          .apply(lambda group: group.head(n=group.shape[0]*3//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          [selected_features]\n",
    "          )\n",
    "x_test = (df_all2['features_train']\n",
    "          .groupby(level='city', as_index=False)\n",
    "          .apply(lambda group: group.tail(n=group.shape[0]*1//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          [selected_features]\n",
    "         )\n",
    "y_train = (df_all2['labels_train']\n",
    "          .groupby('city', as_index=False)\n",
    "          .apply(lambda group: group.head(n=group.shape[0]*3//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          ['total_cases']\n",
    "         )\n",
    "y_test = (df_all2['labels_train']\n",
    "          .groupby('city', as_index=False)\n",
    "          .apply(lambda group: group.tail(n=group.shape[0]*1//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          ['total_cases']\n",
    "         )\n",
    "\n",
    "# auxiliary input\n",
    "z_train = (df_all2['labels_train']\n",
    "          .groupby('city', as_index=False)\n",
    "          .apply(lambda group: group.head(n=group.shape[0]*3//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          ['is_epidemic']\n",
    "         )\n",
    "z_test = (df_all2['labels_train']\n",
    "          .groupby('city', as_index=False)\n",
    "          .apply(lambda group: group.tail(n=group.shape[0]*1//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          ['is_epidemic']\n",
    "         )\n",
    "\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape, z_train.shape, z_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.groupby('city').head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.groupby('city').head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_train.reset_index()['city'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit RF1 on `is_epidemic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_classifier():\n",
    "    return RandomForestClassifier(n_estimators=100, min_samples_split=5, min_samples_leaf=3)\n",
    "\n",
    "def create_model_regressor():\n",
    "    return RandomForestRegressor(n_estimators=100, min_samples_split=5, min_samples_leaf=3)\n",
    "\n",
    "mod1_sj = create_model_classifier()\n",
    "mod1_sj.fit(X = x_train.loc['sj'], y = z_train.loc['sj'])\n",
    "mod1_iq = create_model_classifier()\n",
    "mod1_iq.fit(X = x_train.loc['iq'], y = z_train.loc['iq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to int since we know the label is integer\n",
    "predictions = (y_test.copy()*0).astype('int')\n",
    "\n",
    "predictions.loc['sj'] = mod1_sj.predict(x_test.loc['sj']).astype(int)\n",
    "predictions.loc['iq'] = mod1_iq.predict(x_test.loc['iq']).astype(int)\n",
    "\n",
    "#predictions = require_consecutive(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.loc['iq'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in ['sj', 'iq']:\n",
    "    plt.plot(z_test.loc[city]+2, label='actual')\n",
    "    plt.plot(predictions.loc[city], label='predicted')\n",
    "    plt.title(city)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion matrix\n",
    "because the cool kids have it\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "for city in ['sj', 'iq']:\n",
    "    print(city)\n",
    "    print(confusion_matrix(z_test.loc[city], predictions.loc[city]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check feature importances"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# From benchmark\n",
    "#selected_features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "#                 'reanalysis_dew_point_temp_k', \n",
    "#                 'station_avg_temp_c', \n",
    "#                 'station_min_temp_c']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_imp = mod1_sj.feature_importances_\n",
    "#feat_imp.sort()\n",
    "#feat_imp, mod1_sj.feature_importances_, mod1_sj.feature_importances_.argsort(), \n",
    "xxx = mod1_sj.feature_importances_\n",
    "xxx.sort()\n",
    "xxx#[-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[mod1_sj.feature_importances_.argsort()] # [-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = mod1_iq.feature_importances_\n",
    "xxx.sort()\n",
    "xxx[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[mod1_iq.feature_importances_.argsort()[-10:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append `is_epidemic` to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use computed is_epidemic\n",
    "x_train2 = pd.concat([x_train,z_train], axis=1)\n",
    "x_test2 = pd.concat([x_test,z_test], axis=1)\n",
    "\n",
    "# ignore is_epidemic\n",
    "#x_train2 = x_train.copy()\n",
    "#x_test2 = x_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train RF2 on `total_cases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2_sj = create_model_regressor()\n",
    "mod2_sj.fit(X = x_train2.loc['sj'], y = y_train.loc['sj'])\n",
    "mod2_iq = create_model_regressor()\n",
    "mod2_iq.fit(X = x_train2.loc['iq'], y = y_train.loc['iq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx=mod2_sj.feature_importances_\n",
    "xxx.sort()\n",
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2.columns[mod2_sj.feature_importances_.argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx=mod2_iq.feature_importances_\n",
    "xxx.sort()\n",
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2.columns[mod2_iq.feature_importances_.argsort()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to int since we know the label is integer\n",
    "predictions2 = (y_test.copy()*0).astype('int')\n",
    "\n",
    "predictions2.loc['sj'] = mod2_sj.predict(x_test2.loc['sj']).astype(int)\n",
    "predictions2.loc['iq'] = mod2_iq.predict(x_test2.loc['iq']).astype(int)\n",
    "\n",
    "#predictions2 = require_consecutive(predictions2)\n",
    "\n",
    "predictions2.loc['sj'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(city, mod2_sj.score(x_test2.loc[city], y_test.loc[city])) for city in ['sj','iq']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in ['sj', 'iq']:\n",
    "    plt.plot(y_test.loc[city], label='actual')\n",
    "    plt.plot(predictions2.loc[city], label='predicted')\n",
    "    plt.title(city)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-fit on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare\n",
    "x_retrain = df_all2['features_train'] # [selected_features]\n",
    "y_retrain = df_all2['labels_train']['total_cases']\n",
    "z_retrain = df_all2['labels_train']['is_epidemic']\n",
    "\n",
    "# classifier\n",
    "mod3_sj = create_model_classifier()\n",
    "mod3_sj.fit(X = x_retrain.loc['sj'], y = z_retrain.loc['sj'])\n",
    "mod3_iq = create_model_classifier()\n",
    "mod3_iq.fit(X = x_retrain.loc['iq'], y = z_retrain.loc['iq'])\n",
    "\n",
    "# use calculated is_epidemic\n",
    "x_retrain2 = pd.concat([x_retrain,z_retrain], axis=1)\n",
    "\n",
    "# regressor\n",
    "mod4_sj = create_model_regressor()\n",
    "mod4_sj.fit(X = x_retrain2.loc['sj'], y = y_retrain.loc['sj'])\n",
    "mod4_iq = create_model_regressor()\n",
    "mod4_iq.fit(X = x_retrain2.loc['iq'], y = y_retrain.loc['iq'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set in submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to int since we know the label is integer\n",
    "#predictions3 = (df_all2['submission'][['total_cases']]\n",
    "#               .groupby(level='city', as_index=False)\n",
    "#               .apply(lambda group: group.iloc[n_diff:])\n",
    "#               .reset_index(level=0, drop=True)\n",
    "#               .copy()\n",
    "#               *0\n",
    "#              ).astype('int')\n",
    "\n",
    "predictions3 = (df_all2['submission'][['total_cases']]\n",
    "               .groupby(level='city', as_index=False)\n",
    "               .apply(lambda group: group) #.iloc[n_diff:])\n",
    "               #.reset_index(level=0, drop=True)\n",
    "               .copy()\n",
    "               *0\n",
    "              ).astype('int')\n",
    "\n",
    "x_test = df_all2['features_test']\n",
    "\n",
    "#x_test.groupby('city').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3['is_epidemic'] = False\n",
    "predictions3.loc['sj', 'is_epidemic'] = mod3_sj.predict(x_test.loc['sj', :]).astype(int) # selected_features\n",
    "predictions3.loc['iq', 'is_epidemic'] = mod3_iq.predict(x_test.loc['iq', :]).astype(int) # selected_features\n",
    "\n",
    "# use predicted is_epidemic (unlike before)\n",
    "x_test2 = pd.concat([x_test, predictions3['is_epidemic']], axis=1)\n",
    "\n",
    "predictions3.loc['sj', 'total_cases'] = mod4_sj.predict(x_test2.loc['sj', :]).astype(int) # selected_features\n",
    "predictions3.loc['iq', 'total_cases'] = mod4_iq.predict(x_test2.loc['iq', :]).astype(int) # selected_features\n",
    "\n",
    "#predictions3['total_cases'] = predictions3['is_epidemic'].apply(lambda x: 50 if x==1 else 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = df_all2['submission'].copy()\n",
    "# TODO Will this match indeces properly?\n",
    "# submit['total_cases'] = predictions\n",
    "\n",
    "del submit['total_cases']\n",
    "\n",
    "submit = submit.merge(\n",
    "    predictions3,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "submit['total_cases'] = submit['total_cases'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.groupby('city').head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in ['sj','iq']:\n",
    "    plt.plot(submit.loc[city, 'total_cases'].values, label=city)\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.build_features import make_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(submit.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
