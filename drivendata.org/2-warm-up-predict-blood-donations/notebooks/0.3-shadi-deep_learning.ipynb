{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import load_raw, imply_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_raw()\n",
    "\n",
    "from src.features import append_features\n",
    "\n",
    "df['train'], df['submit'] = map(append_features, [df['train'], df['submit']])\n",
    "\n",
    "cols = imply_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['train'].shape, df['train'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['submit'].shape, df['submit'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['submit'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size=0.3 # 0.3 0. FIXME\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df['train'][cols['features']], \n",
    "    df['train'][cols['target'][0]], \n",
    "    test_size=test_size,\n",
    "    shuffle=True,\n",
    "    stratify=df['train'][cols['target'][0]]\n",
    ")\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_train), y_train.shape[0], sum(y_test), y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outliers and add columns identifying them\n",
    "def preprocess(x_in):\n",
    "    is_outlier = np.tile(np.percentile(x_in, q=95, axis=0), (x_in.shape[0],1))\n",
    "    x_train2 = x_in.values.copy()\n",
    "    x_train2 = np.minimum(x_train2, is_outlier)\n",
    "\n",
    "    #is_outlier = x_train.values > is_outlier\n",
    "    #x_train2 = np.hstack((x_train2, (is_outlier).astype('uint8')))\n",
    "    # x_train2[:5]\n",
    "    return x_train2\n",
    "\n",
    "# map(...) copied from keras.examples.mnist_net2net\n",
    "x_train2, x_test2 = map(preprocess, [x_train, x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess for deep network\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "preprocess = lambda x_in: MinMaxScaler(feature_range=(0, 1), copy=True).fit_transform(x_in)\n",
    "# map(...) copied from keras.examples.mnist_net2net\n",
    "x_train2, x_test2 = map(preprocess, [x_train2, x_test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cols['features'])):\n",
    "    plt.plot(x_train[cols['features'][i]].values)\n",
    "    plt.title('before %s'%i)\n",
    "    plt.show()\n",
    "    plt.plot(x_train2[:,i])\n",
    "    plt.title('after %s'%i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "y_train2, y_test2 = map(keras.utils.to_categorical, [y_train, y_test])\n",
    "y_train2.shape, y_train2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras fully-connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "# utility first layer for avoiding need to move input_shape around\n",
    "from keras.layers import Lambda\n",
    "model.add(Lambda(lambda x: x, input_shape=(x_train.shape[1],)))\n",
    "\n",
    "#from keras.layers import BatchNormalization\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "from keras.layers import Dense\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units= 64, activation='relu'))\n",
    "model.add(Dense(units=  2, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "              #loss='binary_crossentropy',\n",
    "              loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              # optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data\n",
    "print(time.ctime(), 'start fit')\n",
    "history = model.fit(x_train2, y_train2, epochs=1000, batch_size=1024, validation_split=0.1, verbose=0)\n",
    "print(time.ctime(), 'end')\n",
    "\n",
    "model.evaluate(x_train2, y_train2)\n",
    "# [0.47, 0.77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test2, y_test2)\n",
    "# [0.48, 0.78] # no added value on top of auto-sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
