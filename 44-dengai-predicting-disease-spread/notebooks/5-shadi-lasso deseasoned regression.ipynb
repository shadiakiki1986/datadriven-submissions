{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline\n",
    "- deseason features (from statsmodels.tsa and notebook 3.3.1)\n",
    "- [lasso linear](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "  - good at filtering out features when there are many of them\n",
    "- either lasso directly on target, or just use lasso for feature reduction and use another model like RF or OLS\n",
    "\n",
    "TODO\n",
    "- correlation matrix like in the [benchmark](https://github.com/drivendata/benchmarks/blob/master/dengue-benchmark-statsmodels.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.build_features import load_raw\n",
    "\n",
    "df_all = load_raw()\n",
    "\n",
    "# replace with 0.2 output\n",
    "# df_all['labels_train'] = pd.read_pickle('data/processed/is_epidemic.pkl')\n",
    "\n",
    "df_all.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['features_train'].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['labels_train'].head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ['features_train', 'features_test']:\n",
    "    df_all[k] = df_all[k].groupby('city').apply(lambda group: group.fillna(method='ffill'))\n",
    "    assert ~(pd.isnull(df_all[k]).any().any())\n",
    "    print(df_all[k].shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## load deaseasoned from 3.3.1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fn1 = 'data/processed/deseasoned_%s.pkl'\n",
    "df_train = pd.read_pickle(fn1%'train')\n",
    "df_test = pd.read_pickle(fn1%'test')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## choose features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features selected from\n",
    "# https://github.com/drivendata/benchmarks/blob/master/dengue-benchmark-statsmodels.ipynb\n",
    "#selected_features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "#                 'reanalysis_dew_point_temp_k', \n",
    "#                 'station_avg_temp_c', \n",
    "#                 'station_min_temp_c']\n",
    "\n",
    "# all features\n",
    "# selected_features = df_all['features_train'].columns\n",
    "\n",
    "# without year and weekofyear\n",
    "selected_features = np.array(list(set(df_all['features_train'].columns) - set(['year', 'weekofyear'])))\n",
    "\n",
    "# check no missing\n",
    "# assert len(set(selected_features) - set(df_all['features_train'].columns))==0\n",
    "\n",
    "#################################\n",
    "\n",
    "# all original/trend/seasonal features\n",
    "# selected_features = df_train.columns\n",
    "\n",
    "# only trend + weekofyear\n",
    "# import numpy as np\n",
    "# selected_features = np.array([x for x in df_train.columns if x.endswith('_trend')])# or x=='weekofyear'])\n",
    "\n",
    "#################\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = df_all['features_train']\n",
    "\n",
    "for c in selected_features:\n",
    "    for city in ['sj','iq']:\n",
    "        df_train[c].loc[city].plot(figsize=(20,3), label=city)\n",
    "    plt.legend()\n",
    "    plt.title(c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split per city\n",
    "x_train = (df_all['features_train']\n",
    "           #df_train\n",
    "          .groupby(level='city', as_index=False)\n",
    "          .apply(lambda group: group.head(n=group.shape[0]*3//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          [selected_features]\n",
    "          )\n",
    "x_test = (df_all['features_train']\n",
    "          #df_train\n",
    "          .groupby(level='city', as_index=False)\n",
    "          .apply(lambda group: group.tail(n=group.shape[0]*1//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          [selected_features]\n",
    "         )\n",
    "y_train = ( df_all['labels_train']\n",
    "            #df_all['labels_train'].loc[df_train.index]\n",
    "          .groupby('city', as_index=False)\n",
    "          .apply(lambda group: group.head(n=group.shape[0]*3//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          ['total_cases']\n",
    "          # ['is_epidemic'].astype('int')\n",
    "         )\n",
    "y_test = ( df_all['labels_train']\n",
    "            #df_all['labels_train'].loc[df_train.index]\n",
    "          .groupby('city', as_index=False)\n",
    "          .apply(lambda group: group.tail(n=group.shape[0]*1//4))\n",
    "          .reset_index(level=0, drop=True)\n",
    "          ['total_cases']\n",
    "          # ['is_epidemic'].astype('int')\n",
    "         )\n",
    "\n",
    "# y_train = np.log10(y_train+1)\n",
    "# y_test = np.log10(y_test+1)\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.groupby('city').head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.groupby('city').head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_train.reset_index()['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.groupby('city').describe()#tail(n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define custom model for deseasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.utils import check_array\n",
    "\n",
    "\n",
    "class DeSeason(BaseEstimator):\n",
    "    def __init__(self, freq):\n",
    "        self.freq = freq\n",
    "        \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, df_in):\n",
    "        return self.fit_transform(df_in)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        X = check_array(X)\n",
    "        df_interim = []\n",
    "        for jjj in range(X.shape[1]):\n",
    "            res0 = X[:,jjj]\n",
    "            res1 = res0 - res0.mean(axis=0)\n",
    "            res2 = seasonal_decompose(res1, freq=self.freq, two_sided=False)\n",
    "            res2 = pd.DataFrame({\n",
    "                #'original': res0,\n",
    "                'trend': res2.trend, \n",
    "                # FIXME # 'seasonal': res2.seasonal, \n",
    "                'resid': res2.resid\n",
    "            })\n",
    "\n",
    "            # FIXME # res2['original'] = res0\n",
    "            res2 = res2.rename(columns={\n",
    "                'original': \"%s_original\"%jjj,\n",
    "                'trend': \"%s_trend\"%jjj,\n",
    "                'seasonal': \"%s_seasonal\"%jjj,\n",
    "                'resid': \"%s_resid\"%jjj,\n",
    "            })\n",
    "            df_interim.append(res2)\n",
    "\n",
    "        return pd.concat(df_interim, axis=1).fillna(value=0)#.dropna(how='all', axis=0)\n",
    "    \n",
    "# test\n",
    "mdl = DeSeason(freq=2)\n",
    "df_in = np.array([\n",
    "    [1.0,2.0,3.0],[4.0,5.0,6.0],\n",
    "    [1.1,2.0,3.0],[4.1,5.0,6.0],\n",
    "    [1.2,2.0,3.0],[4.2,5.0,6.0],\n",
    "    [1.3,2.0,3.0],[4.3,5.0,6.0],\n",
    "])\n",
    "df_out = mdl.fit_transform(df_in)\n",
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#import statsmodels.api as sm\n",
    "#import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(alpha):\n",
    "    # return RandomForestRegressor(n_estimators=100, min_samples_split=5, min_samples_leaf=3)\n",
    "    # return RandomForestClassifier(n_estimators=100, min_samples_split=5, min_samples_leaf=3)\n",
    "    # return Lasso(alpha=1., normalize=True)\n",
    "    m0 = DeSeason(freq=52)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler\n",
    "    m1 = MinMaxScaler()\n",
    "    \n",
    "    m2 = PolynomialFeatures() # degree=2\n",
    "    \n",
    "    m31 = Lasso(alpha=alpha, normalize=False, positive=True)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/feature_selection.html#l1-based-feature-selection\n",
    "    m32 = SelectFromModel(m31, prefit=False)\n",
    "    m33 = RandomForestRegressor(n_estimators=100, min_samples_split=5, min_samples_leaf=3)\n",
    "    # m33 = FunctionTransformer(lambda X: np.log10(X+1))\n",
    "    # m33 = LinearRegression()\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('deseason', m0),\n",
    "        ('scaler', m1),\n",
    "        ('poly', m2),\n",
    "        ('reducer', m32),\n",
    "        ('regressor', m33),\n",
    "    ])\n",
    "    # model.set_params(anova__k=10, svc__C=.1).fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "mod1_sj = create_model(alpha=1.)\n",
    "mod1_sj.fit(X = x_train.loc['sj'], y = y_train.loc['sj'])\n",
    "mod1_iq = create_model(alpha=.1)\n",
    "mod1_iq.fit(X = x_train.loc['iq'], y = y_train.loc['iq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_features), len(mod1_sj.named_steps['regressor'].coef_), len(mod1_iq.named_steps['regressor'].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_coef = pd.DataFrame({\n",
    "    #'f': selected_features, # \n",
    "    'f': mod1_sj.named_steps['poly'].get_feature_names(), # with polynomial\n",
    "    'sj1': mod1_sj.named_steps['regressor'].coef_, # lasso\n",
    "    # 'sj1': mod1_sj.named_steps['regressor'].feature_importances_, # RF\n",
    "    #'sj2': abs(mod1_sj.named_steps['regressor'].coef_),\n",
    "    'iq1': mod1_iq.named_steps['regressor'].coef_, # lasso\n",
    "    # 'iq1': mod1_iq.named_steps['regressor'].feature_importances_, # RF\n",
    "    #'iq2': abs(mod1_iq.named_steps['regressor'].coef_),\n",
    "}).set_index('f')\n",
    "# .sort_values('sj2', ascending=False)\n",
    "df_coef[(abs(df_coef['iq1'])>.1) | (abs(df_coef['sj1'])>.1)] # lasso\n",
    "# df_coef[(abs(df_coef['iq1'])>.02) | (abs(df_coef['sj1'])>.02)] # RF\n",
    "# df_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[[1,10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict on train to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  alpha = 1\n",
    "\n",
    "# cast to int since we know the label is integer\n",
    "predictions = (y_train.copy()*0).astype('int')\n",
    "\n",
    "predictions.loc['sj'] = mod1_sj.predict(x_train.loc['sj'])\n",
    "predictions.loc['iq'] = mod1_iq.predict(x_train.loc['iq'])\n",
    "#predictions = 10**predictions.astype('int')\n",
    "\n",
    "for city in ['sj', 'iq']:\n",
    "    plt.plot(y_train.loc[city], label='actual')\n",
    "    plt.plot(predictions.loc[city], label='predicted')\n",
    "    plt.title(city)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to int since we know the label is integer\n",
    "predictions = (y_test.copy()*0).astype('int')\n",
    "\n",
    "predictions.loc['sj'] = mod1_sj.predict(x_test.loc['sj'])#.astype(int)\n",
    "predictions.loc['iq'] = mod1_iq.predict(x_test.loc['iq'])#.astype(int)\n",
    "\n",
    "#predictions = (10**predictions).astype('int')\n",
    "predictions.loc['sj'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'sj', mod1_sj.score(x_test.loc['sj'], y_test.loc['sj']), 'iq', mod1_iq.score(x_test.loc['iq'], y_test.loc['iq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in ['sj', 'iq']:\n",
    "    plt.plot(y_test.loc[city], label='actual')\n",
    "    plt.plot(predictions.loc[city], label='predicted')\n",
    "    plt.title(city)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-fit on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_all['features_test']\n",
    "\n",
    "df_test.shape, df_all['labels_train']['total_cases'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'weekofyear' in df_test.columns, 'weekofyear' in df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note avoiding class bias\n",
    "x_retrain = df_all['features_train'][selected_features] # df_train[selected_features]\n",
    "#y_retrain = ( df_all['labels_train']\n",
    "#          .groupby('city', as_index=False)\n",
    "#          .apply(lambda group: group.tail(n=group.shape[0]-52))\n",
    "#          .reset_index(level=0, drop=True)\n",
    "#         )['total_cases']\n",
    "y_retrain = df_all['labels_train']['total_cases']\n",
    "# y_retrain = np.log10(y_retrain+1)\n",
    "\n",
    "mod1_sj = create_model(alpha=1)\n",
    "mod1_sj.fit(X = x_retrain.loc['sj'], y = y_retrain.loc['sj'])\n",
    "mod1_iq = create_model(alpha=.1)\n",
    "mod1_iq.fit(X = x_retrain.loc['iq'], y = y_retrain.loc['iq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set in submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['submission'].shape, df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to int since we know the label is integer\n",
    "predictions = (df_all['submission'][['total_cases']]*0).astype('int')\n",
    "\n",
    "p1 = mod1_sj.predict(df_test.loc['sj', selected_features])#.astype(int)\n",
    "p1 = pd.DataFrame({'pred': p1, 'city': 'sj', 'week_start_date': df_test.loc['sj'].index}).set_index(['city', 'week_start_date'])\n",
    "p2 = mod1_iq.predict(df_test.loc['iq', selected_features])#.astype(int)\n",
    "p2 = pd.DataFrame({'pred': p2, 'city': 'iq', 'week_start_date': df_test.loc['iq'].index}).set_index(['city', 'week_start_date'])\n",
    "\n",
    "p3 = pd.concat([p1,p2], axis=0)\n",
    "predictions = predictions.merge(p3, left_index=True, right_index=True, how='left').fillna(value=0)\n",
    "# predictions['pred'] = 10**predictions['pred'].astype('int')\n",
    "predictions['total_cases'] = predictions['pred']\n",
    "del predictions['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head(n=60).tail(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = df_all['submission'].copy()\n",
    "# TODO Will this match indeces properly?\n",
    "# submit['total_cases'] = predictions\n",
    "\n",
    "del submit['total_cases']\n",
    "\n",
    "submit = submit.merge(\n",
    "    predictions,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "submit['total_cases'] = submit['total_cases'].fillna(value=0)\n",
    "#submit['total_cases'] = (10**submit['total_cases']).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.groupby('city').head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in ['sj','iq']:\n",
    "    submit.loc[city, 'total_cases'].plot(figsize=(20,3), label=city)\n",
    "        \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.build_features import make_submission"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "make_submission(submit.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
