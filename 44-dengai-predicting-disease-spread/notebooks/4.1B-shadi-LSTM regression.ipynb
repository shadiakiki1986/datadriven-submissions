{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change from 3\n",
    "\n",
    "- LSTM instead of RF\n",
    "- normalizing data to [-1,+1]\n",
    "\n",
    "For reference, check https://github.com/drivendata/benchmarks/blob/master/dengue-benchmark-statsmodels.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 0.2 data\n",
    "df_is_epidemic = pd.read_pickle('data/processed/0.2A-is_epidemic.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 5.1 data\n",
    "df_targ = pd.read_pickle('data/processed/5.1B-df_targ.pkl')\n",
    "df_feat_2 = pd.read_pickle('data/processed/5.1B-df_feat_2.pkl')\n",
    "df_meta = pd.read_pickle('data/processed/5.1B-df_meta.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targ.shape, df_is_epidemic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note automatic index matching eventhough not same dimensions\n",
    "df_targ['is_epidemic'] = df_is_epidemic['is_epidemic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targ.tail(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_is_epidemic.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all that make sense\n",
    "selected_features = [x for x in df_feat_2.columns\n",
    "                     if (x.endswith('_trend') and not x.startswith('weekofyear'))\n",
    "                    or x=='weekofyear_original']\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lahead = 10 # 60 yields no classification results\n",
    "batch_size = 16 # smaller batches lead to less loss of data when truncating non-multiples of batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create rolling windows for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stride_group(group, n_back):\n",
    "    out = []\n",
    "    for i in range(n_back):\n",
    "        out.append(group.shift(i).values)\n",
    "        \n",
    "    out = np.stack(out, axis=2)[(n_back-1):, :, :] # drop first lahead\n",
    "    out = np.swapaxes(out, 1, 2)\n",
    "    out = np.flip(out, axis=1) # so that the index=0 is the oldest, and index=4 is latest\n",
    "    return out\n",
    "\n",
    "stride_group_2 = lambda x: stride_group(x, lahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop 1st x rows if they are not a multiple of batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_truncate(df):\n",
    "    return (df.groupby(level='city', as_index=False)\n",
    "              .apply(lambda group: group.tail(group.shape[0] - (group.shape[0]%batch_size)))\n",
    "              .reset_index(level=0, drop=True)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/layers/recurrent/#lstm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Lambda, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_feat_2.loc[~df_meta['submit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note avoiding class bias\n",
    "x_retrain = df_train[selected_features]\n",
    "y_retrain = df_targ.loc[~df_meta['submit']]\n",
    "y_retrain['is_epidemic'] = y_retrain['is_epidemic'].astype('int') # [['total_cases']]\n",
    "x_retrain.shape, y_retrain.shape, y_retrain.groupby('city').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_retrain['is_epidemic'].loc['sj'].plot(label='sj')\n",
    "(y_retrain['is_epidemic']+1.2).loc['iq'].plot(label='iq+1.2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label each epidemic event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_retrain['epidemic_id'] = ((y_retrain['is_epidemic'].astype('int').diff()+1)//2).fillna(value=0).cumsum(axis=0)\n",
    "y_retrain.loc[~y_retrain['is_epidemic'].astype(bool), 'epidemic_id'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yretrain_roll[~yretrain_roll['is_epidemic'].astype(bool)].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yretrain_roll[ yretrain_roll['is_epidemic'].astype(bool)].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yretrain_roll[ yretrain_roll['is_epidemic'].astype(bool)].tail(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xretrain_roll = x_retrain.groupby(level='city').apply(stride_group_2)\n",
    "\n",
    "# drop lahead per city\n",
    "yretrain_roll = (y_retrain\n",
    "                 .groupby(level='city', as_index=False)\n",
    "                 .apply(lambda group: group.iloc[(lahead-1):])\n",
    "                 .reset_index(level=0, drop=True)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for is_epidemic = True\n",
    "for city in ['sj','iq']:\n",
    "    xretrain_roll.loc[city] = xretrain_roll.loc[city][yretrain_roll.loc[city,'is_epidemic'].astype('bool')]\n",
    "    \n",
    "yretrain_roll = yretrain_roll[yretrain_roll['is_epidemic'].astype('bool')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-batchsize-multiple per city\n",
    "for city in ['sj','iq']:\n",
    "    to_drop = xretrain_roll.loc[city].shape[0]%batch_size\n",
    "    print('drop non-multiple', city, to_drop)\n",
    "    xretrain_roll.loc[city] = xretrain_roll.loc[city][(to_drop):]\n",
    "    \n",
    "yretrain_roll = my_truncate(yretrain_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xretrain_roll.loc['sj'].shape, xretrain_roll.loc['iq'].shape, yretrain_roll.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate epidemic max amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yretrain_epidemicmax = (\n",
    "    yretrain_roll[['epidemic_id', 'total_cases']]\n",
    "    .groupby('epidemic_id')\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .rename(columns={'total_cases': 'epidemic_max'})\n",
    ")\n",
    "yretrain_epidemicmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yretrain_roll = yretrain_roll.reset_index().merge(\n",
    "    yretrain_epidemicmax,\n",
    "    on = 'epidemic_id',\n",
    "    how='left'\n",
    ").set_index(['city', 'week_start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yretrain_roll.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yretrain_roll[yretrain_roll['epidemic_id']==2].head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100,\n",
    "              input_shape=(lahead, len(selected_features)),\n",
    "              batch_size=batch_size,\n",
    "              activation='linear'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    # model.add(Dense(1, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.add(Dropout(0.2))\n",
    "    # model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "mod1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in ['sj', 'iq']:\n",
    "    print(city)\n",
    "    #if city=='sj': continue # FIXME fitting sj model\n",
    "    mod1[city] = create_model()\n",
    "    #if city=='iq': continue # FIXME skipping iq model\n",
    "    mod1[city].summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# actual fit\n",
    "for city in ['sj', 'iq']:\n",
    "    print(city)\n",
    "    print(time.ctime(),'fit start')\n",
    "    history = mod1[city].fit(\n",
    "             xretrain_roll.loc[city][yretrain_roll['is_epidemic']],\n",
    "             yretrain_roll.loc[city, 'epidemic_max'][yretrain_roll['is_epidemic']],\n",
    "             batch_size=batch_size,\n",
    "             epochs=20, #250, #500, # 1000,\n",
    "             verbose=2,\n",
    "             #validation_data=None,\n",
    "             shuffle=False\n",
    "        )\n",
    "    print(time.ctime(),'fit end')\n",
    "    \n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    #plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.title(city)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot trained result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xretrain_roll.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yretrain_roll.groupby('city').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(city, np_in, index):\n",
    "    print(city, np_in.shape)\n",
    "    np_pred = mod1[city].predict(np_in, batch_size=batch_size)\n",
    "    print(np_pred.shape)\n",
    "    out = pd.DataFrame({\n",
    "        'is_epidemic': np_pred.squeeze(), \n",
    "        'city': city, \n",
    "        'week_of_year': index,\n",
    "    }).set_index(['city', 'week_of_year'])\n",
    "    return out\n",
    "\n",
    "yretrain_pred = pd.concat([\n",
    "    my_predict(\n",
    "        city, \n",
    "        xretrain_roll.loc[city][yretrain_roll.loc[city, 'is_epidemic'].astype('bool')], \n",
    "        yretrain_roll.loc[city][yretrain_roll.loc[city, 'is_epidemic'].astype('bool')].index\n",
    "    )\n",
    "    for city in ['sj','iq']\n",
    "], axis=0)\n",
    "\n",
    "# reverse log10 transform\n",
    "# y_pred['total_cases'] = ((10**((y_pred['total_cases']).clip(upper=3)))-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yretrain_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in ['sj','iq']:\n",
    "    (yretrain_pred.loc[city]['is_epidemic']).plot(label='predicted + 1.2')\n",
    "    yretrain_roll.loc[city]['is_epidemic'].astype('int').plot(label='actual', figsize=(20,3))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict `is_epidemic` on submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_submit = df_feat_2.loc[ df_meta['submit'], selected_features]\n",
    "\n",
    "xsubmit_roll = x_submit.groupby(level='city').apply(stride_group_2)\n",
    "\n",
    "# drop non-batch_size multiple\n",
    "for city in ['sj','iq']:\n",
    "    xsubmit_roll.loc[city] = xsubmit_roll.loc[city][(xsubmit_roll.loc[city].shape[0]%batch_size):]\n",
    "    \n",
    "# choose any field from x_submit just to get the index\n",
    "ysubmit_roll = (x_submit[['weekofyear_original']]\n",
    "                 .groupby(level='city', as_index=False)\n",
    "                 .apply(lambda group: group.iloc[(lahead-1):])\n",
    "                 .reset_index(level=0, drop=True)\n",
    "                *0\n",
    "                )    \n",
    "ysubmit_roll = my_truncate(ysubmit_roll)\n",
    "\n",
    "ysubmit_pred = pd.concat([my_predict(city, xsubmit_roll.loc[city], ysubmit_roll.loc[city].index) for city in ['sj','iq']], axis=0)\n",
    "\n",
    "# reverse log10 transform\n",
    "# y_pred['total_cases'] = ((10**((y_pred['total_cases']).clip(upper=3)))-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in ['sj','iq']:\n",
    "    (ysubmit_pred.loc[city]['is_epidemic']).plot(figsize=(20,3), label=city)\n",
    "\n",
    "plt.title('submission')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysubmit_pred.to_pickle('data/processed/4.1A-ysubmit_pred.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100,\n",
    "              input_shape=(lahead, len(selected_features)),\n",
    "              batch_size=batch_size,\n",
    "              activation='linear'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Lambda(lambda x: x*10)) # TODO x*30 caused the re-fit on complete dataset to blow up\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-fit on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_retrain = df_all['features_train'][selected_features]\n",
    "y_retrain = df_all['labels_train'][['total_cases']]\n",
    "\n",
    "xretrain_scaled, scaler_xretrain = my_scale(x_retrain)\n",
    "# yretrain_scaled, scaler_yretrain = my_scale(y_retrain)\n",
    "yretrain_scaled = y_retrain\n",
    "scaler_yretrain = None\n",
    "\n",
    "xretrain_roll = xretrain_scaled.groupby(level='city').apply(stride_group)\n",
    "yretrain_roll = (yretrain_scaled\n",
    "                 .groupby(level='city', as_index=False)\n",
    "                 .apply(lambda group: group.iloc[lahead:])\n",
    "                 .reset_index(level=0, drop=True)\n",
    "                )\n",
    "\n",
    "for city in ['sj','iq']:\n",
    "    xretrain_roll.loc[city] = xretrain_roll.loc[city][(xretrain_roll.loc[city].shape[0]%batch_size):]\n",
    "    \n",
    "yretrain_roll = my_truncate(yretrain_roll)\n",
    "\n",
    "mod1 = {}\n",
    "for city in ['sj', 'iq']:\n",
    "    print(city)\n",
    "    mod1[city] = create_model()\n",
    "    mod1[city].summary()\n",
    "    print(time.ctime(),'fit start')\n",
    "    history = mod1[city].fit(\n",
    "             xretrain_roll.loc[city],\n",
    "             yretrain_roll.loc[city],\n",
    "             batch_size=batch_size,\n",
    "             epochs=1000,\n",
    "             verbose=0,\n",
    "             #validation_data=None,\n",
    "             shuffle=False)\n",
    "    print(time.ctime(),'fit end')\n",
    "    \n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    #plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.title(city)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set in submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['submission'].loc['sj'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_submit = (df_all['features_test']\n",
    "          .groupby(level='city', as_index=False)\n",
    "          .apply(lambda group: group.iloc[n_diff:])\n",
    "          .reset_index(level=0, drop=True)\n",
    "          [selected_features]\n",
    "          )\n",
    "xsubmit_scaled, scaler_xsubmit = my_scale(x_submit)\n",
    "xsubmit_roll = xsubmit_scaled.groupby(level='city').apply(stride_group)\n",
    "\n",
    "\n",
    "for city in ['sj','iq']:\n",
    "    xsubmit_roll.loc[city] = xsubmit_roll.loc[city][(xsubmit_roll.loc[city].shape[0]%batch_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (df_all['submission'][['total_cases']]\n",
    "               .groupby(level='city', as_index=False)\n",
    "               .apply(lambda group: group.iloc[(lahead+n_diff+1):])\n",
    "               .reset_index(level=0, drop=True)\n",
    "               .copy()\n",
    "               *0\n",
    "              ).astype('int')\n",
    "\n",
    "def my_predict(city):\n",
    "    np_pred = mod1[city].predict(xsubmit_roll.loc[city], batch_size=batch_size)\n",
    "    d1 = predictions.loc[city].shape[0]\n",
    "    d2 = xsubmit_roll.loc[city].shape[0]\n",
    "    return np.concatenate([np.zeros((d1-d2,1)), np_pred], axis=0)\n",
    "\n",
    "predictions.loc['sj', 'total_cases'] = my_predict('sj')\n",
    "predictions.loc['iq', 'total_cases'] = my_predict('iq')\n",
    "\n",
    "# FIXME cannot really apply scaler_ytest on the predictions\n",
    "#predictions.loc[:] = scaler_ytest.inverse_transform(predictions).astype(int)\n",
    "predictions['total_cases'] = predictions['total_cases'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = df_all['submission'].copy()\n",
    "# TODO if this matches indeces properly, review the complicated merge in 3.1\n",
    "submit['total_cases'] = predictions\n",
    "submit = submit.fillna(value=0)\n",
    "submit['total_cases'] = submit['total_cases'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in ['sj','iq']:\n",
    "    plt.plot(submit.loc[city, 'total_cases'].values, label=city)\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.build_features import make_submission"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "make_submission(submit.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
