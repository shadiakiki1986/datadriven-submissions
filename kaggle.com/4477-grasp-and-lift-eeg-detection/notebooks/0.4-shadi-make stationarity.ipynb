{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.tsa.stattools as ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read example train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_pts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_load(subj_ids:list, series_ids:list):\n",
    "    features_all = []\n",
    "    targets_all = []\n",
    "    for i1 in subj_ids:\n",
    "        for i2 in series_ids:\n",
    "            for i3, fn in [\n",
    "                ('features', 'data/raw/train/subj%i_series%i_data.csv'%(i1, i2)),\n",
    "                ('targets', 'data/raw/train/subj%i_series%i_events.csv'%(i1, i2)),\n",
    "            ]:\n",
    "                print('status:', i1, i2, i3)\n",
    "                xxx_i = pd.read_csv(fn)\n",
    "                xxx_i['subj_id'] = i1\n",
    "                xxx_i['series_id'] = i2\n",
    "                xxx_i = xxx_i.set_index(['subj_id', 'series_id', 'id']).astype('int16')\n",
    "                xxx_i = xxx_i[::downsample_pts] # downsample\n",
    "                if i3=='features':\n",
    "                    features_all.append(xxx_i)\n",
    "                else:\n",
    "                    targets_all.append(xxx_i)\n",
    "            \n",
    "    features_all = pd.concat(features_all, axis=0)\n",
    "    targets_all = pd.concat(targets_all, axis=0)\n",
    "    return features_all, targets_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features, train_targets = my_load(subj_ids = [1], series_ids = [x+1 for x in range(8)])\n",
    "train_features.shape, train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf2human(result):\n",
    "    \"\"\"\n",
    "    utility function: ADF result for humans\n",
    "    https://stats.stackexchange.com/questions/73921/how-to-interpret-the-results-of-adf-test-using-sas-arima#74508\n",
    "    \"\"\"\n",
    "    return 'stationary' if result[1] <= 0.05 else ('could be non-stationary' if result[0] > -2.5 else 'stationary')\n",
    "\n",
    "adf2human([10, .01]), adf2human([10, .08]), adf2human([-10, .01]), adf2human([-10, .08])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADF test on first 1k pts\n",
    "\n",
    "result is 'not stationary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = train_features.columns[0]\n",
    "x = train_features[k].head(n=1000)\n",
    "# x -= x.reset_index().index*(600)/1000\n",
    "x.reset_index()[k].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ts.adfuller(x)\n",
    "k, result, adf2human(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pywt wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "ecgsignal = x\n",
    "[c, l]=pywt.wavedec(ecgsignal,8,'coif5'); \n",
    "a9=wrcoef('a',c,l,'coif5',8);\n",
    "coeffs=pywt.wavedec(ecgsignal,'coif5', level=8)\n",
    "renc=pywt.waverec(coeffs, 'coif5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "cA, cD = pywt.dwt([1, 2, 3, 4], 'db1')\n",
    "pywt.idwt(cA, cD, 'db1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pywt.waverec([cA[:1], cD[:1]], [1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scipy wavelet\n",
    "\n",
    "To replace with https://github.com/aaren/wavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "t = np.linspace(-1, 1, 200, endpoint=False)\n",
    "sig  = np.cos(2 * np.pi * 7 * t) + signal.gausspulse(t - 0.4, fc=2)\n",
    "widths = np.arange(1, 31)\n",
    "cwtmatr = signal.cwt(sig, signal.ricker, widths)\n",
    "plt.imshow(cwtmatr, extent=[-1, 1, 31, 1], cmap='PRGn', aspect='auto',\n",
    "           vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwtmatr.shape, sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cwtmatr).transpose().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sig).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cwtmatr).transpose().sum(axis=1).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://github.com/aaren/wavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wavelets import WaveletAnalysis\n",
    "\n",
    "# given a signal x(t)\n",
    "x = np.random.randn(1000)\n",
    "# and a sample spacing\n",
    "dt = 0.1\n",
    "\n",
    "wa = WaveletAnalysis(x, dt=dt)\n",
    "\n",
    "# wavelet power spectrum\n",
    "power = wa.wavelet_power\n",
    "\n",
    "# scales \n",
    "scales = wa.scales\n",
    "\n",
    "# associated time vector\n",
    "t = wa.time\n",
    "\n",
    "# reconstruction of the original data\n",
    "rx = wa.reconstruction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'ori': x, 'rec': rx+5}).head(n=100).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Diff': x-rx}).head(n=100).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply on original feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = train_features.columns[0]\n",
    "x = train_features[k].head(n=10000).values\n",
    "\n",
    "# and a sample spacing\n",
    "dt = 0.001\n",
    "\n",
    "wa = WaveletAnalysis(x, dt=dt)\n",
    "\n",
    "# wavelet power spectrum\n",
    "power = wa.wavelet_power\n",
    "\n",
    "# scales \n",
    "scales = wa.scales\n",
    "\n",
    "# associated time vector\n",
    "t = wa.time\n",
    "\n",
    "# reconstruction of the original data\n",
    "rx = wa.reconstruction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'ori': x, 'rec': np.real(rx)+5}).plot(figsize=(20,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'diff': x-np.real(rx)}).plot(figsize=(20,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADF on wavelet reconstruction\n",
    "\n",
    "still non-stationary, but closer to stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ts.adfuller(np.real(rx))\n",
    "k, result, adf2human(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ts.adfuller(x)\n",
    "k, result, adf2human(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make stationary piece-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = train_features.columns[0]\n",
    "rx = []\n",
    "n_px = 1000\n",
    "for i in range(10000//n_px):\n",
    "    x = train_features[k].head(n=(i+1)*n_px).tail(n=n_px).values\n",
    "\n",
    "    # and a sample spacing\n",
    "    dt = 0.001\n",
    "\n",
    "    wa = WaveletAnalysis(x, dt=dt)\n",
    "\n",
    "    # reconstruction of the original data\n",
    "    rx.append(np.real(wa.reconstruction()))\n",
    "    \n",
    "rx = np.concatenate(rx, axis=0)\n",
    "rx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_features[k].head(n=10*1000).values\n",
    "y = pd.DataFrame({'ori': x, 'rec': rx})\n",
    "\n",
    "y.plot(figsize=(20,3))\n",
    "plt.show()\n",
    "\n",
    "y['diff'] = y['ori'] - y['rec']\n",
    "\n",
    "y['diff'].plot(figsize=(20,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(n=5000).tail(n=1000).plot(figsize=(20,3))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subtract global mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = train_features.columns[0]\n",
    "x = train_features[k].head(n=10*1000)\n",
    "y = train_features.head(n=10*1000)\n",
    "s = (y - y.min(axis=0)) / (y.max(axis=0) - y.min(axis=0)) # scale to 0-1\n",
    "m = s.mean(axis=1)\n",
    "\n",
    "n = s[k] - m\n",
    "\n",
    "y = pd.DataFrame({'ori': x, 'mean': m, 'new': n})\n",
    "\n",
    "y['ori'].plot(figsize=(20,3))\n",
    "plt.show()\n",
    "\n",
    "y['mean'].plot(figsize=(20,3))\n",
    "plt.show()\n",
    "\n",
    "y['new'].plot(figsize=(20,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in train_features.columns:\n",
    "    x = train_features[k].head(n=10*1000)\n",
    "    x.plot()\n",
    "    plt.title(k)\n",
    "    plt.show()\n",
    "    \n",
    "    s[k].plot()\n",
    "    plt.title(k)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = s.corr(method='pearson')\n",
    "corr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(corr_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[corr_df.loc['Fp1'][corr_df.loc['Fp1'] > 0.4].index].head(n=10000).plot(alpha=.5)\n",
    "plt.show()\n",
    "\n",
    "s[corr_df.loc['Fp1'][corr_df.loc['Fp1'] > 0.4].index].head(n=10000).mean(axis=1).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=s[corr_df.loc['Fp1'][corr_df.loc['Fp1'] > 0.4].index].head(n=10000)\n",
    "df2 = df.values-df.mean(axis=1).values.reshape((-1,1))\n",
    "df2 = pd.DataFrame(df2, index=df.index, columns=df.columns)\n",
    "df.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot(alpha=.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
