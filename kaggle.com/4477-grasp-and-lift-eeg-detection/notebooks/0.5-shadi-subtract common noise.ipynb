{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.tsa.stattools as ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read example train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_pts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_load(subj_ids:list, series_ids:list):\n",
    "    features_all = []\n",
    "    targets_all = []\n",
    "    for i1 in subj_ids:\n",
    "        for i2 in series_ids:\n",
    "            for i3, fn in [\n",
    "                ('features', 'data/raw/train/subj%i_series%i_data.csv'%(i1, i2)),\n",
    "                ('targets', 'data/raw/train/subj%i_series%i_events.csv'%(i1, i2)),\n",
    "            ]:\n",
    "                print('status:', i1, i2, i3)\n",
    "                xxx_i = pd.read_csv(fn)\n",
    "                xxx_i['subj_id'] = i1\n",
    "                xxx_i['series_id'] = i2\n",
    "                xxx_i = xxx_i.set_index(['subj_id', 'series_id', 'id']).astype('int16')\n",
    "                xxx_i = xxx_i[::downsample_pts] # downsample\n",
    "                if i3=='features':\n",
    "                    features_all.append(xxx_i)\n",
    "                else:\n",
    "                    targets_all.append(xxx_i)\n",
    "            \n",
    "    features_all = pd.concat(features_all, axis=0)\n",
    "    targets_all = pd.concat(targets_all, axis=0)\n",
    "    return features_all, targets_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features, train_targets = my_load(subj_ids = [1], series_ids = [x+1 for x in range(8)])\n",
    "train_features.shape, train_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subtract global mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_min = train_features.min(axis=0)\n",
    "train_features_max = train_features.max(axis=0)\n",
    "train_features_min.to_pickle('data/processed/train_features_min.pkl')\n",
    "train_features_max.to_pickle('data/processed/train_features_max.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_df = lambda y: (y - y.min(axis=0)) / (y.max(axis=0) - y.min(axis=0)) # scale to 0-1\n",
    "train_features = scale_df(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in train_features.columns:\n",
    "    x = train_features[k].head(n=10*1000)\n",
    "    x.plot(figsize=(20,3))\n",
    "    plt.title(k)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = train_features.corr(method='pearson')\n",
    "corr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.loc['Fp1'] > .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(corr_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rm_mean_corr(s, corr_df):\n",
    "    df3 = []\n",
    "    for feat_i in corr_df.index:\n",
    "        print(feat_i)\n",
    "        feat_corr1 = corr_df.loc[feat_i] > 0.7\n",
    "        feat_corr2 = corr_df.loc[feat_i][feat_corr1]\n",
    "        feat_corr3 = feat_corr2.index\n",
    "        print(feat_corr3)\n",
    "        \n",
    "        if len(feat_corr3) <= 1:\n",
    "            df3.append(s[[feat_i]])\n",
    "            continue\n",
    "        \n",
    "        # wontdo\n",
    "        # df=s[feat_corr3] * feat_corr2.reshape((1,-1)) / feat_corr2.sum() # weighted by correlation\n",
    "        \n",
    "        # subtract mean\n",
    "        df0 = s[feat_corr3]\n",
    "        df1 = df0.mean(axis=1)\n",
    "        df2 = df0[feat_i] - df1\n",
    "        df3.append(df2)\n",
    "        \n",
    "    df3 = pd.concat(df3, axis=1)\n",
    "    df3.columns = s.columns\n",
    "    return df3\n",
    "\n",
    "new_features = rm_mean_corr(train_features, corr_df)\n",
    "new_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = pd.read_pickle('data/processed/0.5-features_minus_spatial_noise.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in new_features.columns:\n",
    "    new_features[k].head(n=10000).plot(figsize=(20,3))\n",
    "    plt.title(k)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "new_features.to_pickle('data/processed/0.5-features_minus_spatial_noise.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=train_features.shape[1]) # same number of features\n",
    "pca_features =  pca.fit_transform(train_features)\n",
    "pca_features = pd.DataFrame(pca_features, index=new_features.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in pca_features.columns:\n",
    "    pca_features[k].head(n=10000).plot(figsize=(20,3))\n",
    "    plt.title(k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot complete but downsampled\n",
    "for k in pca_features.columns:\n",
    "    pca_features[k].iloc[::100].plot(figsize=(20,3))\n",
    "    plt.title(k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
